{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62593ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The torchaudio backend is switched to 'soundfile'. Note that 'sox_io' is not supported on Windows.\n",
      "The torchaudio backend is switched to 'soundfile'. Note that 'sox_io' is not supported on Windows.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from typing import Optional, List, Dict, Any\n",
    "import time\n",
    "import psutil\n",
    "import GPUtil\n",
    "import whisper\n",
    "from whisperx import load_align_model, align\n",
    "from whisperx.diarize import DiarizationPipeline, assign_word_speakers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd191ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_wav(input_file: str, output_file: Optional[str] = None) -> None:\n",
    "    \"\"\"\n",
    "    Converts an audio file to WAV format using FFmpeg.\n",
    "\n",
    "    Args:\n",
    "        input_file: The path of the input audio file to convert.\n",
    "        output_file: The path of the output WAV file. If None, the output file will be created by replacing the input file\n",
    "        extension with \".wav\".\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not output_file:\n",
    "        output_file = os.path.splitext(input_file)[0] + \".wav\"\n",
    "\n",
    "    command = f'ffmpeg -i \"{input_file}\" -vn -acodec pcm_s16le -ar 44100 -ac 1 \"{output_file}\"'\n",
    "\n",
    "    try:\n",
    "        subprocess.run(command, shell=True, check=True)\n",
    "        print(f'Successfully converted \"{input_file}\" to \"{output_file}\"')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f'Error: {e}, could not convert \"{input_file}\" to \"{output_file}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a28501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(audio_file: str, model_name: str, device: str = \"cuda\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Transcribe an audio file using a speech-to-text model.\n",
    "\n",
    "    Args:\n",
    "        audio_file: Path to the audio file to transcribe.\n",
    "        model_name: Name of the model to use for transcription.\n",
    "        device: The device to use for inference (e.g., \"cpu\" or \"cuda\").\n",
    "\n",
    "    Returns:\n",
    "        A dictionary representing the transcript, including the segments, the language code, and the duration of the audio file.\n",
    "    \"\"\"\n",
    "    model = whisper.load_model(model_name, device)\n",
    "    result = model.transcribe(audio_file)\n",
    "\n",
    "    language_code = result[\"language\"]\n",
    "    return {\n",
    "        \"segments\": result[\"segments\"],\n",
    "        \"language_code\": language_code,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3116ad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_segments(\n",
    "    segments: List[Dict[str, Any]],\n",
    "    language_code: str,\n",
    "    audio_file: str,\n",
    "    device: str = \"cuda\",\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Align the transcript segments using a pretrained alignment model.\n",
    "\n",
    "    Args:\n",
    "        segments: List of transcript segments to align.\n",
    "        language_code: Language code of the audio file.\n",
    "        audio_file: Path to the audio file containing the audio data.\n",
    "        device: The device to use for inference (e.g., \"cpu\" or \"cuda\").\n",
    "\n",
    "    Returns:\n",
    "        A dictionary representing the aligned transcript segments.\n",
    "    \"\"\"\n",
    "    model_a, metadata = load_align_model(language_code=language_code, device=device)\n",
    "    result_aligned = align(segments, model_a, metadata, audio_file, device)\n",
    "    return result_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7d5f0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diarize(audio_file: str, hf_token: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Perform speaker diarization on an audio file.\n",
    "\n",
    "    Args:\n",
    "        audio_file: Path to the audio file to diarize.\n",
    "        hf_token: Authentication token for accessing the Hugging Face API.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary representing the diarized audio file, including the speaker embeddings and the number of speakers.\n",
    "    \"\"\"\n",
    "    diarization_pipeline = DiarizationPipeline(use_auth_token=hf_token)\n",
    "    diarization_result = diarization_pipeline(audio_file)\n",
    "    return diarization_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0ef521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_speakers(\n",
    "    diarization_result: Dict[str, Any], aligned_segments: Dict[str, Any]\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Assign speakers to each transcript segment based on the speaker diarization result.\n",
    "\n",
    "    Args:\n",
    "        diarization_result: Dictionary representing the diarized audio file, including the speaker embeddings and the number of speakers.\n",
    "        aligned_segments: Dictionary representing the aligned transcript segments.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries representing each segment of the transcript, including the start and end times, the\n",
    "        spoken text, and the speaker ID.\n",
    "    \"\"\"\n",
    "    result_segments = assign_word_speakers(\n",
    "        diarization_result, aligned_segments\n",
    "    )\n",
    "    results_segments_w_speakers: List[Dict[str, Any]] = []\n",
    "    for result_segment in result_segments['segments']:\n",
    "        try:\n",
    "            results_segments_w_speakers.append(\n",
    "                {\"start\": result_segment[\"start\"],\n",
    "                \"end\": result_segment[\"end\"],\n",
    "                \"text\": result_segment[\"text\"],\n",
    "                \"speaker\": result_segment[\"speaker\"]})\n",
    "        except KeyError:\n",
    "            results_segments_w_speakers.append(\n",
    "                {\n",
    "                \"start\": result_segment[\"start\"],\n",
    "                \"end\": result_segment[\"end\"],\n",
    "                \"text\": result_segment[\"text\"],\n",
    "                \"speaker\": \" \"\n",
    "                })\n",
    "        \n",
    "    return results_segments_w_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a963eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_and_diarize(\n",
    "    audio_file: str,\n",
    "    hf_token: str,\n",
    "    model_name: str,\n",
    "    device: str = \"cuda\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Transcribe an audio file and perform speaker diarization to determine which words were spoken by each speaker.\n",
    "\n",
    "    Args:\n",
    "        audio_file: Path to the audio file to transcribe and diarize.\n",
    "        hf_token: Authentication token for accessing the Hugging Face API.\n",
    "        model_name: Name of the model to use for transcription.\n",
    "        device: The device to use for inference (e.g., \"cpu\" or \"cuda\").\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries representing each segment of the transcript, including the start and end times, the\n",
    "        spoken text, and the speaker ID.\n",
    "    \"\"\"\n",
    "    \n",
    "    seg = []\n",
    "    st = []\n",
    "    et =[]\n",
    "    sp = []\n",
    "    tr = []\n",
    "    transcript = transcribe(audio_file, model_name, device)\n",
    "    aligned_segments = align_segments(\n",
    "        transcript[\"segments\"], transcript[\"language_code\"], audio_file, device\n",
    "    )\n",
    "    diarization_result = diarize(audio_file, hf_token)\n",
    "    results_segments_w_speakers = assign_speakers(diarization_result, aligned_segments)\n",
    "    \n",
    "    # Print the results in a user-friendly way\n",
    "    for i, segment in enumerate(results_segments_w_speakers):\n",
    "        seg.append(i+1)\n",
    "        st.append(segment['start'])\n",
    "        et.append(segment['end'])\n",
    "        sp.append(segment['speaker'])\n",
    "        tr.append(segment['text'])\n",
    "        '''\n",
    "        print(f\"Segment {i + 1}:\")\n",
    "        print(f\"Start time: {segment['start']:.2f}\")\n",
    "        print(f\"End time: {segment['end']:.2f}\")\n",
    "        print(f\"Speaker: {segment['speaker']}\")\n",
    "        print(f\"Transcript: {segment['text']}\")\n",
    "        print(\"\")'''\n",
    "    df = pd.DataFrame(data = [seg,st,et,sp,tr],columns=['Segment','Start time','End time','Speaker','Transcript'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64ac4054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted \"F:/28 Jul, 1.10 pm_ Pushkar Naath MotoGP.aac\" to \"F:/28 Jul, 1.10 pm_ Pushkar Naath MotoGP.wav\"\n"
     ]
    }
   ],
   "source": [
    "convert_to_wav(\"F:/28 Jul, 1.10 pm_ Pushkar Naath MotoGP.aac\", \"F:/28 Jul, 1.10 pm_ Pushkar Naath MotoGP.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96fc3a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "audio_file = (\n",
    "        \"F:/28 Jul, 1.10 pm_ Pushkar Naath MotoGP.wav\"\n",
    "    )\n",
    "model_name = 'medium'\n",
    "device = 'cuda'\n",
    "hf_token = os.environ.get('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "835112ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to align segment (\" So technically I am holding my close to 60000 people, 6 to 70000 people.\"): backtrack failed, resorting to original...\n",
      "Failed to align segment (\" 6...\"): no characters in this segment found in model dictionary, resorting to original...\n",
      "Failed to align segment (\" 4.\"): no characters in this segment found in model dictionary, resorting to original...\n",
      "Failed to align segment (\" 106...\"): no characters in this segment found in model dictionary, resorting to original...\n",
      "Failed to align segment (\" So, album music event or something, that's part of your ticket?\"): backtrack failed, resorting to original...\n",
      "Failed to align segment (\" There are smaller countries, there are larger countries.\"): backtrack failed, resorting to original...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.6. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file C:\\Users\\neeraj\\.cache\\torch\\pyannote\\models--pyannote--segmentation\\snapshots\\c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b\\pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu118. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\AppData\\Local\\Temp\\ipykernel_3012\\2399853664.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\neeraj\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_3012\\\\2399853664.py'</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\AppData\\Local\\Temp\\ipykernel_3012\\2944235091.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">30</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">transcribe_and_diarize</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\neeraj\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_3012\\\\2944235091.py'</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\AppData\\Local\\Temp\\ipykernel_3012\\4184368119.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">13</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">diarize</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\neeraj\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_3012\\\\4184368119.py'</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\whisperx\\diarize.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">19</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model = Pipeline.from_pretrained(model_name, use_auth_token=use_auth_token)    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, audio, min_speakers=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, max_speakers=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>):                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>19 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>segments = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model(audio, min_speakers=min_speakers, max_speakers=max_speaker    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">20 │   │   </span>diarize_df = pd.DataFrame(segments.itertracks(yield_label=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>))                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21 │   │   </span>diarize_df[<span style=\"color: #808000; text-decoration-color: #808000\">'start'</span>] = diarize_df[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>].apply(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">lambda</span> x: x.start)                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22 │   │   </span>diarize_df[<span style=\"color: #808000; text-decoration-color: #808000\">'end'</span>] = diarize_df[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>].apply(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">lambda</span> x: x.end)                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\pyannote\\audio\\core\\pipeline.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">324</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">321 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">hasattr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"preprocessors\"</span>):                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">322 │   │   │   </span>file = ProtocolFile(file, lazy=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.preprocessors)                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">323 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>324 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.apply(file, **kwargs)                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">325 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">326 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, device):                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">327 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Send pipeline to `device`\"\"\"</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_diarization.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">496</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">apply</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">493 │   │   │   </span>embeddings = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">494 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">495 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>496 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>embeddings = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.get_embeddings(                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">497 │   │   │   │   </span>file,                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">498 │   │   │   │   </span>binarized_segmentations,                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">499 │   │   │   │   </span>exclude_overlap=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embedding_exclude_overlap,                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_diarization.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">337</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_embeddings</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">334 │   │   │   </span>mask_batch = torch.vstack(masks)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">335 │   │   │   # (batch_size, num_frames) torch.Tensor</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">336 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>337 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>embedding_batch: np.ndarray = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._embedding(                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">338 │   │   │   │   </span>waveform_batch, masks=mask_batch                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">339 │   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">340 │   │   │   # (batch_size, dimension) np.ndarray</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_verification.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">363</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">360 │   │   </span>wav_lens[too_short] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1.0</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">361 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">362 │   │   </span>embeddings = (                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>363 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.classifier_.encode_batch(signals, wav_lens=wav_lens)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">364 │   │   │   </span>.squeeze(dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">365 │   │   │   </span>.cpu()                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">366 │   │   │   </span>.numpy()                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\speechbrain\\pretrained\\interfaces.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">973</span> in          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">encode_batch</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 970 │   │   # Computing features and embeddings</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 971 │   │   </span>feats = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.mods.compute_features(wavs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 972 │   │   </span>feats = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.mods.mean_var_norm(feats, wav_lens)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 973 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>embeddings = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.mods.embedding_model(feats, wav_lens)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 974 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> normalize:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 975 │   │   │   </span>embeddings = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.hparams.mean_var_norm_emb(                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 976 │   │   │   │   </span>embeddings, torch.ones(embeddings.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>], device=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.device)           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\speechbrain\\lobes\\models\\ECAPA_TDNN.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">498</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">495 │   │   </span>x = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.mfa(x)                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">496 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">497 │   │   # Attentive Statistical Pooling</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>498 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.asp(x, lengths=lengths)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">499 │   │   </span>x = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.asp_bn(x)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">500 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">501 │   │   # Final linear transformation</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\speechbrain\\lobes\\models\\ECAPA_TDNN.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">271</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">268 │   │   │   </span>attn = x                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">269 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">270 │   │   # Apply layers</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>271 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>attn = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.conv(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.tanh(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.tdnn(attn)))                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">272 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">273 │   │   # Filter out zero-paddings</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">274 │   │   </span>attn = attn.masked_fill(mask == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">float</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"-inf\"</span>))                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\speechbrain\\lobes\\models\\ECAPA_TDNN.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">81</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 78 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 79 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, x):                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 80 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\" Processes the input tensor x and returns an output tensor.\"\"\"</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 81 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.norm(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.activation(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.conv(x)))                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 82 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 83 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 84 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">Res2NetBlock</span>(torch.nn.Module):                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\speechbrain\\nnet\\CNN.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">441</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 438 │   │   │   │   </span>+ <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.padding                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 439 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 440 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 441 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>wx = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.conv(x)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 442 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 443 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.unsqueeze:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 444 │   │   │   </span>wx = wx.squeeze(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">313</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 310 │   │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.padding, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dilation, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.groups)                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 311 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 312 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor) -&gt; Tensor:                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 313 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._conv_forward(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 314 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 315 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 316 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">Conv2d</span>(_ConvNd):                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">309</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_conv_forward</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 306 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.conv1d(F.pad(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._reversed_padding_repeated_twice, mode=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">sel</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 307 │   │   │   │   │   │   │   </span>weight, bias, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.stride,                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 308 │   │   │   │   │   │   │   </span>_single(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>), <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dilation, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.groups)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 309 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.conv1d(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, weight, bias, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.stride,                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 310 │   │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.padding, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dilation, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.groups)                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 311 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 312 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor) -&gt; Tensor:                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\AppData\\Local\\Temp\\ipykernel_3012\\2399853664.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'C:\\\\Users\\\\neeraj\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_3012\\\\2399853664.py'\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\AppData\\Local\\Temp\\ipykernel_3012\\2944235091.py\u001b[0m:\u001b[94m30\u001b[0m in \u001b[92mtranscribe_and_diarize\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'C:\\\\Users\\\\neeraj\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_3012\\\\2944235091.py'\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\AppData\\Local\\Temp\\ipykernel_3012\\4184368119.py\u001b[0m:\u001b[94m13\u001b[0m in \u001b[92mdiarize\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'C:\\\\Users\\\\neeraj\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_3012\\\\4184368119.py'\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\whisperx\\diarize.py\u001b[0m:\u001b[94m19\u001b[0m in \u001b[92m__call__\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.model = Pipeline.from_pretrained(model_name, use_auth_token=use_auth_token)    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m17 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__call__\u001b[0m(\u001b[96mself\u001b[0m, audio, min_speakers=\u001b[94mNone\u001b[0m, max_speakers=\u001b[94mNone\u001b[0m):                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m19 \u001b[2m│   │   \u001b[0msegments = \u001b[96mself\u001b[0m.model(audio, min_speakers=min_speakers, max_speakers=max_speaker    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m20 \u001b[0m\u001b[2m│   │   \u001b[0mdiarize_df = pd.DataFrame(segments.itertracks(yield_label=\u001b[94mTrue\u001b[0m))                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m21 \u001b[0m\u001b[2m│   │   \u001b[0mdiarize_df[\u001b[33m'\u001b[0m\u001b[33mstart\u001b[0m\u001b[33m'\u001b[0m] = diarize_df[\u001b[94m0\u001b[0m].apply(\u001b[94mlambda\u001b[0m x: x.start)                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m22 \u001b[0m\u001b[2m│   │   \u001b[0mdiarize_df[\u001b[33m'\u001b[0m\u001b[33mend\u001b[0m\u001b[33m'\u001b[0m] = diarize_df[\u001b[94m0\u001b[0m].apply(\u001b[94mlambda\u001b[0m x: x.end)                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\pyannote\\audio\\core\\pipeline.py\u001b[0m:\u001b[94m324\u001b[0m in \u001b[92m__call__\u001b[0m      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m321 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mhasattr\u001b[0m(\u001b[96mself\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mpreprocessors\u001b[0m\u001b[33m\"\u001b[0m):                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m322 \u001b[0m\u001b[2m│   │   │   \u001b[0mfile = ProtocolFile(file, lazy=\u001b[96mself\u001b[0m.preprocessors)                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m323 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m324 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.apply(file, **kwargs)                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m325 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m326 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mto\u001b[0m(\u001b[96mself\u001b[0m, device):                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m327 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Send pipeline to `device`\"\"\"\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_diarization.py\u001b[0m:\u001b[94m496\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mapply\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m493 \u001b[0m\u001b[2m│   │   │   \u001b[0membeddings = \u001b[94mNone\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m494 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m495 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m496 \u001b[2m│   │   │   \u001b[0membeddings = \u001b[96mself\u001b[0m.get_embeddings(                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m497 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfile,                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m498 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mbinarized_segmentations,                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mexclude_overlap=\u001b[96mself\u001b[0m.embedding_exclude_overlap,                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_diarization.py\u001b[0m:\u001b[94m337\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mget_embeddings\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m334 \u001b[0m\u001b[2m│   │   │   \u001b[0mmask_batch = torch.vstack(masks)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m335 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# (batch_size, num_frames) torch.Tensor\u001b[0m                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m336 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m337 \u001b[2m│   │   │   \u001b[0membedding_batch: np.ndarray = \u001b[96mself\u001b[0m._embedding(                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m338 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mwaveform_batch, masks=mask_batch                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m339 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m340 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# (batch_size, dimension) np.ndarray\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_verification.py\u001b[0m:\u001b[94m363\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m__call__\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m360 \u001b[0m\u001b[2m│   │   \u001b[0mwav_lens[too_short] = \u001b[94m1.0\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m361 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m362 \u001b[0m\u001b[2m│   │   \u001b[0membeddings = (                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m363 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.classifier_.encode_batch(signals, wav_lens=wav_lens)                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m364 \u001b[0m\u001b[2m│   │   │   \u001b[0m.squeeze(dim=\u001b[94m1\u001b[0m)                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m365 \u001b[0m\u001b[2m│   │   │   \u001b[0m.cpu()                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m366 \u001b[0m\u001b[2m│   │   │   \u001b[0m.numpy()                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\speechbrain\\pretrained\\interfaces.py\u001b[0m:\u001b[94m973\u001b[0m in          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mencode_batch\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 970 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Computing features and embeddings\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 971 \u001b[0m\u001b[2m│   │   \u001b[0mfeats = \u001b[96mself\u001b[0m.mods.compute_features(wavs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 972 \u001b[0m\u001b[2m│   │   \u001b[0mfeats = \u001b[96mself\u001b[0m.mods.mean_var_norm(feats, wav_lens)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 973 \u001b[2m│   │   \u001b[0membeddings = \u001b[96mself\u001b[0m.mods.embedding_model(feats, wav_lens)                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 974 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m normalize:                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 975 \u001b[0m\u001b[2m│   │   │   \u001b[0membeddings = \u001b[96mself\u001b[0m.hparams.mean_var_norm_emb(                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 976 \u001b[0m\u001b[2m│   │   │   │   \u001b[0membeddings, torch.ones(embeddings.shape[\u001b[94m0\u001b[0m], device=\u001b[96mself\u001b[0m.device)           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\speechbrain\\lobes\\models\\ECAPA_TDNN.py\u001b[0m:\u001b[94m498\u001b[0m in        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m495 \u001b[0m\u001b[2m│   │   \u001b[0mx = \u001b[96mself\u001b[0m.mfa(x)                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m496 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m497 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Attentive Statistical Pooling\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m498 \u001b[2m│   │   \u001b[0mx = \u001b[96mself\u001b[0m.asp(x, lengths=lengths)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m499 \u001b[0m\u001b[2m│   │   \u001b[0mx = \u001b[96mself\u001b[0m.asp_bn(x)                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m500 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m501 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Final linear transformation\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\speechbrain\\lobes\\models\\ECAPA_TDNN.py\u001b[0m:\u001b[94m271\u001b[0m in        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m268 \u001b[0m\u001b[2m│   │   │   \u001b[0mattn = x                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m269 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m270 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Apply layers\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m271 \u001b[2m│   │   \u001b[0mattn = \u001b[96mself\u001b[0m.conv(\u001b[96mself\u001b[0m.tanh(\u001b[96mself\u001b[0m.tdnn(attn)))                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m272 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m273 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Filter out zero-paddings\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m274 \u001b[0m\u001b[2m│   │   \u001b[0mattn = attn.masked_fill(mask == \u001b[94m0\u001b[0m, \u001b[96mfloat\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33m-inf\u001b[0m\u001b[33m\"\u001b[0m))                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\speechbrain\\lobes\\models\\ECAPA_TDNN.py\u001b[0m:\u001b[94m81\u001b[0m in \u001b[92mforward\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 78 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 79 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, x):                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 80 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\" Processes the input tensor x and returns an output tensor.\"\"\"\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 81 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.norm(\u001b[96mself\u001b[0m.activation(\u001b[96mself\u001b[0m.conv(x)))                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 82 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 83 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 84 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mRes2NetBlock\u001b[0m(torch.nn.Module):                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\speechbrain\\nnet\\CNN.py\u001b[0m:\u001b[94m441\u001b[0m in \u001b[92mforward\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 438 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m+ \u001b[96mself\u001b[0m.padding                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 439 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 440 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 441 \u001b[2m│   │   \u001b[0mwx = \u001b[96mself\u001b[0m.conv(x)                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 442 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 443 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.unsqueeze:                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 444 \u001b[0m\u001b[2m│   │   │   \u001b[0mwx = wx.squeeze(\u001b[94m1\u001b[0m)                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m:\u001b[94m313\u001b[0m in \u001b[92mforward\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 310 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.padding, \u001b[96mself\u001b[0m.dilation, \u001b[96mself\u001b[0m.groups)                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 311 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 312 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 313 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._conv_forward(\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m.weight, \u001b[96mself\u001b[0m.bias)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 314 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 315 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 316 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mConv2d\u001b[0m(_ConvNd):                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m:\u001b[94m309\u001b[0m in \u001b[92m_conv_forward\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 306 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m F.conv1d(F.pad(\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m._reversed_padding_repeated_twice, mode=\u001b[96msel\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 307 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mweight, bias, \u001b[96mself\u001b[0m.stride,                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 308 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m_single(\u001b[94m0\u001b[0m), \u001b[96mself\u001b[0m.dilation, \u001b[96mself\u001b[0m.groups)                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 309 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m F.conv1d(\u001b[96minput\u001b[0m, weight, bias, \u001b[96mself\u001b[0m.stride,                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 310 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.padding, \u001b[96mself\u001b[0m.dilation, \u001b[96mself\u001b[0m.groups)                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 311 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 312 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = transcribe_and_diarize(audio_file, hf_token, model_name,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ff686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e7f046",
   "metadata": {},
   "source": [
    "# Trying Out each module independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de4fe9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transcript = transcribe(audio_file, model_name, device)\n",
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1878cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for d in transcript['segments']:\n",
    "    text +=d['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8b9579a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I don't think so we'll be allowed but we'll be able to share some photographs with you. Last night we shared a fantastic post on Instagram and the dark night, some port of dark night. So essentially we work in 24 hours. Weather's been very bad. So whatever time we can, whenever you want to try, sunlight, more sunlight, rain, day, whatever, a lot more. I think the main work is to fix the draft. No, it's just art. Like I was mentioning that he might be a chopper, but he's doing a good job. And that's the passion of the man. Very good. So we're not filming this. We have some other team on the other end. Everyone has their specific skills here. And if one falls off the plane, you get it. Everyone is there since day T minus 30 days or T minus 365 days. So let's start with the design and where the idea really came from. How did you get the concept? So we have been in racing 2011-12. 12, 13, 14 we did World Superbike. Amit Chandel, my director of racing, my cousin right now, he has a family business invested in it. And then we won the pole position also in the race. And then after some time we thought, let's show that company to someone else. And then we moved ahead in our relevant business. So I moved into operations to Europe. Amit is the one who sets up MotoGP in the country. He moved to Indonesia. Vaibhav, Baldi is Canadian national. Vaibhav also moved back to Canada. And then we assembled again. And then we assembled again in 2015. We started discussing that now we have seen MotoGP a lot. Now how to bring it back to India. That's when we started working on the project. And we realized it's still entertainment. So we were lucky that the current government has the vision to make motorsport as recognized as motorsport. So in 2019 it got recognized as motorsport. And we were very happy. We were still working on how to get MotoGP. So what first we studied, I will not take it on record. But we can discuss afterwards. But first we said that let's study what went wrong with Formula 1. So we started reading Honorable Supreme Court judgment, their studies and everyone's experience. I came to Formula 1 to see him. And then we in a group discussed for a long time that why it failed. Someone said it failed because of entertainment. Someone said it failed because of income tax. Someone said it was government issue. Someone said it was Formula 1 issue. But by and large, it came to us before time. Formula 1 was not ready. How Indian authorities will react. Indian authorities were not ready. What Formula 1 will come into. So we studied all the judgments line by line. And then we started reading that it's a normal process. So if you now go to Germany to work. If you go for some business meeting, you get a 30 day visa. You get a business visa. And you conduct business meeting. You are not supposed to work. Then come back. And if you have to work, you have to apply for a work visa. Apply for local tax card. Get health card. And then go there. And by the way, if you go to Europe, you won't get paid for 2 months at least. Because for the entire documentation process takes 2 months. You have to open your bank account. You have to open your yellow card. You have to open your tax card. Once your tax card is ready, then only your salary comes in. The entire process is of 2 months. So same happened with Formula 1 technically. They came in here. They thought they are coming as a right piece process. But technically they landed up in a different node. There was also an issue with the amount of taxation. That's why the taxation problem happened. Because their physical establishment was proven. They were not, I mean, the Honorable Supreme Court said that we don't have any problem with you doing business here. We have problem with you doing business and not paying your relevant taxes. So that's why we thought how we should bring MotoGP. That they should not face the same challenge. No, racing is not a big thing. But how to make sure that they race for 7 years and 7 years more. So then we were able to convince them that this is how we should structure our contract. This is how you should have your jurisdiction. This is what we should earn out of this. You want your entry in the Indian market. You get that entry in the Indian market to publicize your name. And to let people know that it's faster than Formula 1. We touched 366. The straight stretch which you are seeing, we are expecting somewhere around 370 on Ducati. So it's faster prototype on planet. Interesting. So it's a 7 year agreement. It's a 7 year agreement. Then we signed a 7 year agreement. And we convinced them that if we structure our deal in such a way. For example, broadcast was one. So till now, if Formula 1 goes in any country, they send the broadcasting right. But here, to make sure we adhere with the law of land, we sold the broadcasting right. Fair Street Sports. Fair Street Sports sold the broadcasting right. And this is happening for the first time. For the first time. So there are many such instances which we did to make sure that we pay taxes to the government. From the earning, MotoGP just come and as a racing team, they do the race and go back. And you said that 7 years more they can extend it. Yes, we have right of first refusal. ROFR. So how is the UP government involved exactly in this? Because Yogi has also been promoting it. Yes, so when MotoGP came here for the first time, they saw the track and everything. They checked the track and saw it's very, I mean after all the Formula 1 crisis, they said I want to understand first whether government is with you or not. You guys are enthusiastic. You have told me agreement and everything is in place. But I want to understand the government support. This happened last year September, August. August. August last year. So we are all three, I mean even before that when we were discussing with MotoGP team, we had couple of discussions with UP government and they were very impressed. When they invited them, he went to Honorable CM's office to meet him and CM asked what all you need. He said I need security. He said yes, we will assure you for 100% security. Then Honorable CM asked at what speed bikes will run. He said I am not going to answer that. He said Tamil Nadu is asking at what speed bikes will run. So Tamil Nadu said at 360. CM was shocked to know that. He said okay, my state bikes will run at this speed and there will be a world cup. What you need, I will give you. Assure us some security. The track is in poor condition. Can you help us in developing it? He said yes, we will do. Please come. That's the one word. Kamilo came out. Until and unless he didn't give us the contract to sign. Then me and Rohit were in Delhi and Kamilo and my partners were in Lucknow. We got split somehow due to weather condition of similar type. We planned to fly but weather was not in that favor. Our chopper couldn't take off so we split at night 4 o'clock. But then Kamilo came out and said send the contract. We are ready. Assurance from head of state, that's what he wanted to hear. It should not happen that we do it and later on government says that we are not. So the government has invested in... Not invested, government cannot invest in a private property. So first government said that, we requested them that first give us NOCP. Because EDA and JP had some litigation issue. So he said that first you give me NOCP. It should not happen that I do the event, you come and don't open the... So the main gate is still locked. I saw that. It's still locked, there is a stamp of UP government. So they have to open, so we have to take NOCP from them. NOCP from JP, NOCP from court that we are okay to race. You don't come and trouble us afterwards. So there is entire thing that you have to work on. It's not just that you get the right to start racing and... The race is the easiest. Race is the easiest part. So who has invested you? We as far as sports. To fix the track. To fix the track and to get the race and everything. We have been investing in multiple ventures. We have been investing in this venture from last 2 years. How much have you earmarked for this like the entire risk? How much are you investing? So for this year we are expecting somewhere around 300 plus. And ROI is to be expected in how long? We will break even soon. In the first half? We are trying to make sure that how we should break even in the first year. Because A. we should not make it too revenue centric. You know this is, this should be going to survive for 7 years. If I earn more money on ticket, make it impossible for normal people to afford. I don't put entertainment all around here. People leave at 3 o'clock. Someone coming from Gurgaon and he will only turn up on day 1. Like I came when Formula 1 was happening. I only came on one day. What day? From Noida. From sector 50 to greater Noida I only... So that's what I said. We were discussing, we discussed this a lot. What were the failures of Formula 1? So I came from Noida sector 50 in 2011 to see the race. And then I never came on the day 2. There is too much of a trauma. Day 2. I still remember that. From Noida 51 to here, day 2 I never came. Traffic jams and all. Traffic jam here, hours and after 3 o'clock, you will okay. We spent almost 2 hours in coming. Now 3 o'clock race is over, 40 minutes. Now I have to go back again. Right. It was a headache. So you had to do some entertainment around. So then instead of being a promoter, I started realizing from a spectator, from a common man perspective, what should I do, what should I not do, how should I hold people here without putting gun on their heads. I think we just missed an important point. Before we went on to the blueprint of what we need to do, I think there was a SWAT team who sat down and they were studying global sports. Sports is moving beyond just the contest. It's a destination tour. Pre the event, while the event happens and how to linger on the crowd. His vision was to create, this is a 100 acre property. You get people from adjoining states coming in. From Himachal, Jaipur. Because India as a country is evolving in its motorcycling spirit. Lifestyle motorcycling is coming in. So he wanted to create a program which is lasted not for the 3 hours of the race, but people came, experienced the race and then hung around here. So, technically I gave target to all of our team members to think that how should we hold someone here and he should stay here for 3 days. That's the first building block. How someone should stay from Friday to Sunday and make this as a weekend destination. Something like a German beer fest or something. Exactly. October 45th. So then we realized let's split the event into two parts. 9 to 4, 4 to 9. Different. So race gets over at 4 o'clock. If everyone starts going on, area gets sold, there is a traffic crisis. What if I start entertainment? What if I start music? What if I start food festival? There is a food engagement. So there is a big food festival which is coming in all the areas. So if you can ask someone to bring the map, I will show them. So then we are going on a philosophy, entertainment for all, food for all. That video we can see. That video we can play. That VIP village? Just to give a sense. So we said entertainment for all and food for all. Food for everyone. It's raining, give me a second. Covers. Covers on. I was just thinking when will you stop and say it started raining. It's such a beautiful place but it's so sad. Yeah. Nothing happens. I think the whole idea when it started and happened was that this will become a city. It's raining. It just went for a six in that sense. Should we put the covers now? Okay, WM is on. You can't have a city. What if it's like a waste town? Coming here it's like a waste town. The turn 4 one. It was depressing. Now we look forward to come. Because when we come there is something new we see. People come. WM will not be sold. New energy flow. Okay. I just see this. Just call him and he will insert. He will come. I am also leaving. Okay. So you see this is turn 4. We are doing some milling here. Going straight in this last corner. Because the moment someone comes at 300 plus speed and take a turn. There is a possibility that we might get a strip and escape. So we have to remove the road and put more gravel here. So we are doing some milling and that's what we see here. So this milling was built for an F1 track. Yes. Now we have to change it. No, no, no. That is another thing. So first we discuss. So coming back to the point of entertainment. I will come to the F1 part as well. Right also. Because I don't miss telling these things. So then we realize that how we should make this as a weekend destination. How someone should come on Friday. This day till Sunday. We are trying to find out. Tie up with some spectator economy hotels. So that if a visitor is coming. So be able to find a budgeted hotel for their stay. For 3 days. And see the race. And be part of this entertainment. And get lost in this area for next 3 days. So people are ready to spend. But there is not much hotels in greater Gujarat. We are tying up with some local hotels. And we are starting some buses. And ferrying them. And taking them from different routes in Noida. And greater Noida. And bringing them here. And taking them back. From Delhi also. From Delhi also. Aero city too. Aero city as well. And we are also starting feeder buses. Right. So. So keep it here. I will keep it here. Keep it here. It is getting hot. This is steam building. Where we are steam building. This is pit building. From here bikes will go out. They will come on the track. This is the track. And then this comes in this way. So it is divided into 4 zones. North, west, south, east. This is the area which is locked. This is north. And then east. And then south. And this is your main. So. This is a new building. Yes. No. It is this one. So we are sitting here. And we will be on this side. We are doing repair here as well. Here as well. Here as well. Here as well. And some there. So everywhere. Yeah. The turns primarily. The turns. Yeah. So. So every stand you see. So this is the stand. Behind the stand is 1,25 meter area. So this was the main spectator zone. We call it F1 village. Now we call it Motu village. Yeah. Village. Yeah. It is a rest room, if you want sedan bed. They can hold 30,000 people. But then we have the capacity of one lakh. One lakh, 355 per unit. I cannot leave my 70,000 people. Right? Then does on entertainment here. Some entertainment here and food at every stand. But three more, two more entertainment rooms for 30,000 people. So technically I am holding my close to 60,000 people. 60 to 70,000 people. It is very durable. This is the cutting position. I can keep cutting things. And this. This is cutting position for display like wheels. Yeah. Okay. Okay. close to 60,000 people, 60 to 70,000 people. Just to add to his point, the existing families of OBGP in India is close to 54 million. That's entire Europe, 57 million. And that's entire Europe together. And that's his vision also to democratize. I mean, it's not a niche race, it's not only meant for people who really follow premium soccer and stuff like that. The idea is to democratize. AC Nelson. I'll give you some handbook. Yeah, I think that makes sense. Because we were talking about that also, that you know, where is the families? Yes, India has been marked for 2 billion also. We have existing families of 57. And that's a lag, you've got to put together 52 or 53. Yeah. And these are what age category? I'll send you the age category as well and how many people watch the race app also. 18 to 35 to answer your question, but we'll give you a booklet. If you can talk, because MotoGP has a huge women audience. Yeah. And that is something which is very, very big. I mean, globally, it's about 85% of their audience is women. Pushpa, why don't you talk about how the response to the city views and... So, I'll... Yeah, let's go one by one. I'll... So, we started planning entertainment for everyone. So, that was the first plan. And then since this area has a capacity of 20,000 parking, so we said let's call for buses. Let's carry those buses from the hotels. And we have then signed a contract with some hotels and getting those people from there to the hotel. So, one problem solved, then came in food and... Thank you. And then traffic. Because these are the four points, number one, number two, and then this is another diagram. So, if everyone starts leaving, it will be a chaos at 4 o'clock. But if I do entertainment and these three zones, it's sorted. So, who's the entertainment partner? There are multiple. We are having a presentation for them now, but we are still in the process of finalizing. I hope by this week it will be finalized and we'll be announcing. So, there are three picnic stands also. So, those people who are paying 2500 rupees, they will also come and they'll have some umbrella sitting. They can come with their mats and enjoy the days and be part of it. And can they bring their own food? Food and all, there will be food truck. With every stand there is a food truck and multiple food stands. So, they just need to come? They just need to come. They can come naturally. They can park themselves. With their mat and especially for bikes. So, you see that every area we have marked as motorcycle parking. Motorcycle parking. And it's a specific designated area near to this stand. Because it's a motorcycle world, right? Bikes are considered as inferior medium of parking or transport when you go to any mall or any office. Cars will have this grand entry by China. We reverse that. Yeah, we reverse that. So, there will be an arc here. Anyone who is coming on bike, because we got to know a lot of people are coming on their bike from Mumbai, Ahmedabad, Jaipur. Yeah, they are on bike day. And Hayausa and Ducati and KTM. Fancy bikes. Yeah, the fancy bikes. So, we have kept a special motorcycle parking area and an arc for them. So that they can come, we can welcome them. It's there. Some kind of a cloud. Some kind of a cloud, yeah. You know, unlike cricket which is like a stadium and people congregate there. This is a city. It's like segregated into various sections. VIP village will give you a different experience. The cheaper tickets, we didn't want to lose out on that. You know, it's a day out for them. So, food trucks was a great idea. We said we can't do premium food but we will create zones. So, some stunts happening, some food happening, some music happening. Every section is a self-sustaining center. Because walking from one zone to the other is like a few kilometers. So, every zone is on its own. It's a stadium on its own. Yeah. 30,000 capacity. Every corner. And you can top up to 800 tickets also. Yeah, so. Yeah. And then once everything, this was done, the UP government supported us. Then we saw the broadcasting right. Then we started finding our ticketing partner. So, we realized we should find a ticketing partner who has done premium events. And who can hold this type of event and who can promote event actually. So, then we tied up with Bookmyshow after Jio. We broadcasted this on Jio Cinema for the first time. Before this, everyone has to pay for a specific amount on OTT. On other channels. But Jio Cinema is free of cost. So, our promise to MotoGP was, you give me access to select a right broadcasting partner. You don't go after me. Let me go after reach. So, we selected Jio Cinema because it was open for all. Everyone, it's like a doodh darshan for everyone. Right. Anyone can watch it. For free. Next year it will be free. Free, it's nice. Yeah. So, then we signed a deal with Jio Cinema. And I am, we are having fantastic reception. They are also on OTT as well as linear sports 18 HD. It's showing our races. Sports 18 HD as well. Sports 18 HD is the linear and Jio Cinema is OTT. So, what is your partnership with them look like? With the micromanaging? We have signed a 3 year deal. And then you can, since it's a 7 year deal, you will... We will see how it goes. Did you expect more of the viewership to come from OTT or? OTT is giving us more viewership. Traditionally it's a sport that also has more audience. Then race is in your hand, right? And that's why, that was one of the major parameter to select a broadcasting partner. We should have one OTT platform and we should be working with one partner, not two. Because I have anyways a lot of things to take care of. And then Bukmashra was also an extension of that. That came afterwards. Bukmashra was never a preference or we went through a proper selection process. So, in a very close time. And very, so whichever we have selected, be it broadcasting, be it ticketing, was very close time. Even events. Even events. We announced our broadcasting, my final first race was at 2.30. We announced at 1 o'clock. Though we were ready at 3-1, we selected the partner. The other partner was very reluctant not to let go. And same with Bukmashra. My best league was ready. My partner was ready to offer what not. To get more OTT. I want more OTT. But I have to focus on one side that if you are able to promote race very well. What was the name of the company? KTM. And who was OTT? It was Sony, it was Discovery. Discovery. Euro has a huge impact on the field from the front. What is it now? After recording. Like Geo Cinema because of the IPF thing. The leech, because they show FIFA, they have shown. My belief always was that it should be available to everyone. Here you don't have to pay. How you pay? Maybe from next year if they make it a video, what is the result? So, something will come. But people will buy it next year. And it has reached a level of people which earlier did not have access to OTT platform. People will watch on their phone. Plus from next year we are going to cover regional languages as well. In MotoGP. So, will be available in this time? Not now, but now we are trying to find out how the leech is happening. So, only English this season. Only English this season. But Indian GP, we are looking at it, should be broadcasted and everything. But next year onwards, it should be in regional languages. Because this year, another target. So, now this is broadcast and everything. Then my next target was how to make MotoGP a household name. I think I achieved my target yesterday. Same for you? No, yesterday also. I came from Varanasi yesterday. I didn't tell this story to everyone. But I told my partners who were freaked out at the airport. So, Palmi was roaming around. And I was in glasses. So, there was some racing team with us. We went to see Varanasi to do some more racing events. Someone said that, look, there is a racing team with t-shirt. MotoGP Bharat is also coming in September. That guy was talking to next to me. I believe that flight was going to Ahmedabad. And because we are doing a city tour in Ahmedabad this week. So, I completely freaked out. That airport, someone talking next to me, taking name of MotoGP Bharat. I said, okay, almost achieved. Not achieved, almost achieved. So, then to make it successful, we started our plan to... ...show the race in 24 cities. And we started from Delhi. Rohit has always been the guy who make sure that we do it well. He is the one who gave the idea. So, the whole idea like I was saying is to democratize the race in India. And to give you some more numbers, premium motorcycles share like 1.6%. But that is poised to grow at 20% worldwide. Yeah, it is a small place. But the important thing is that people are transitioning into a lifestyle. But there you have head space to grow. Correct. And when you create a platform for racing which is a global idea. It really changes the style. And... Siddharth. And... Get him carried on. No, I had a little meeting. I just came in and saw him pass by. Please carry on. Siddharth is actually sporting officer. He is also a very important call in the ring to make this happen. Vishal, you might want to talk about roads of riding in India. Yeah, I am just showing what we did in Delhi. So, we called for an event. A gathering. And we announced that we are going to do MotoGP. City Tour. And we are going to celebrate 1000 GP. In two days, we got almost 200 plus entries. And finally, we have to close at 370. We went to GNL stadium at 6 o'clock in the morning. Realizing that now close to 200 people will come. And then suddenly we were shocked to see close to 800 people were there on the road. And then we did a ride from GNL to Saivarao. I will show you something in bits and pieces. And then I will show you the video. This is the Saivarao. We have just bike and two people. Just bike and two of us. So, then we started this culture. We opened the link. And then people come and register. And then they participate. No charging. No. See. It was a completely user friendly event. We were anticipating 200. 800 people. This is Ghaulaguan. People must be wondering. What? What happened? 6 o'clock. You know the best part was Mike Belief's message. He said that he will come to Pondi at 6 o'clock. As if he will come to Pondi. And Kumar was like freaked out when he saw the numbers. And the super bikes, the noise we created. The stand speed. And what they made it to stop them finally? D11. Saivarao. Vyasam. Then we did Hyderabad. Same type of response. Now we are doing Hyderabad. Then we move to Bangalore. Bangalore. And to Jaipur. How many cities did you do? Our target is 24 cities. Till? Till September. So we announced our Hyderabad. This is the resulting in twist here. Yeah. Natty Natty. Same has happened with Hyderabad also. Close to... I think Shan was there. Yeah, Shan was there. And then we announced our Ahmedabad. So Hyderabad also had turn up for 400+. And for Ahmedabad we have... 300 by now. 49 is the mark. You know, Ritu, just... All this excitement might put you off, that it might be rash. I want to state something very important. They say, you know, the great power comes with responsibility. Our races are planned in such a way that a form is sent to everybody. An indemnity form and safety protocols. Everybody has to fill up that form. There is an ambulance, there is a pilot vehicle. So everything is so synchronized that it really gives you a lot of confidence that it's not about just driving fast. It's not about driving a big machine. And as a racing promoter in India, we're saying that tracks are for racing and roads are for riding. So we're really promoting that. Every single individual fills up that form. And it's an online form. And there's a do and don'ts as well. So that's a very, very important medium. And this is what we are promoting with the local government as well. And the traffic police. Everyone loses their life on the road by racing. Because we don't have this type of facility. When you go, it doesn't show you what road safety measures we are taking here. So then we are saying, real men race on track. Road is for driving. You just drive on the road. Because we didn't have that infrastructure, there is 57 million motor GP fans. 54 rather. And then there is, if you put a racing infrastructure and build a culture where people come on their bike over the weekend and race here. And then go on track. Then go on road and drive safely. Because here, if anything happens to you, we have riding gear, we have hospitals, we have helicopters to take care of you. But if anything happens on road, every 5 km they don't have emergency response service. It's a 5 km motor GP is happening here. You come and race. So what will the format be over the 3 days? How will it be organized? So first day it's trials. Second day it's pole position plus sprint races. So we have universal format, Canada and Sherwood. And third day is the main motor GP race. And every day all the 3 segments will race. Motor 2, motor 3, motor GP. And all the 3 races will keep on happening. However, to make Saturday more attractive, motor GP has added sprint races now. And what will the business look like? It looks like 300 persons are looking at this. It looks like, yeah. So how much will you do with that? What will be the largest investment? The largest investment I believe will be in my racing rides, sponsorships, branding, making sure it's an entertainment for all. So largely there are 2 heads under which you spend. One is the license fees that you get such an IP to the country and the second is the organization. To a great extent, both of them are almost equal. So there's a great deal that goes into putting this event up. Right from getting the equipment, custom gear, getting them to race here on the race weekend, putting up that grand show, building it up over months, through marketing, everything that you see is a cost. And then till the time they depart. So all that is a cost. So it's largely these 2 heads. Could you give me a sense of how much is the license fee? I said it's almost equal. 50-50? Yeah, almost. And then we have to create the entertainment as well for everyone. That's the organization part. There's the whole event that has to be put up. A to Z, everything. What about sponsorships? What kind of sponsorships are you expecting? It's a very limited game. We are bombarded with a lot of sponsors to make them part of this event. But we have very limited seats. One title, two co-sponsors, six associates. That's all. That is the way that the international event is? That's the international format. Six sponsorships? No, six associate sponsorships. Then next year we have two co-sponsorships. And the highest tier is obviously the title. Do you have some of the games being closed? Yeah, we are in the process of closing at least four of them. UP Government has become our co-sponsor. One of the main sponsors. One of the big sponsors. Big sponsors. And they are associating with us in a big way. Including the departments, you can discuss. Invest UP is engaging with us. They see a bright opportunity for talking to brands that are associated with MotoGP. Because MotoGP, unlike any other sport, unlike football or cricket, the brands aren't just associated as sponsors. This is an industry in itself. There's the entire automobile industry, there are factories, factory teams, there are OEMs, auto-beams, auxiliary, ancillary, so many industries supporting this industry. So if you are a petrol partner or lubricant partner, you actually supply your lubricant. You are not just for the namesake. If you are a tyre partner, you supply a tyre. If you are a helmet partner, you supply a helmet. Not just a brand. Not just a brand. If you are a glass partner, you actually supply the sunglasses. So you said ROI, it looks like it could break even in your lap? It could break even. It could. We are very much aware of it. But my main target is to make it accessible to everyone. But the tickets are now gone. It's gone. So now coming back to tickets. So when we announced our ticket, we had a promise to everyone that we'll make history here. So we'll sell tickets for less than $10. Never happened in MotoGP. So we sold it for $800. That day we went to announce, give the first ticket to our little chief minister of the village. Then we announced our ticket. We were trending on Twitter. One was Yogi for MotoGP, then second, YogiGP. Somehow people were trending. And within 2 hours, 800 categories were sold out. I was shocked to see that people were buying only 2 categories of tickets. 40,000 and 800. Nothing in between. And it's not like 800 and 40,000 were placed next to each other. One was on top, one was at last. Once they consumed 40,000 per ticket, they started buying 30,000 per ticket. If you go to MotoGP, if you go to BookMyShow, and don't trust me. It was sold out. And then 30,000 got sold out. And 40,000 also was sold out. But then we had to release tickets from our quota, which we promised for ourselves. And to give it to people. Now 40,000. Now 30,000 sold out. 800 sold out. 40,000 almost sold out. Fast filling. Next category is 25,000. People are not touching anywhere in between. They are buying a few tickets. But they are only buying the higher category tickets. Which is quite a surprise for us. It's an elite sport, right? It's not elite. Our target is to make sport for everyone. But, after COVID, as Rohit said, one fine day, people have realized it's now or never. So, India is ready to spend. If you give them a good venue to spend, a good category to spend their money, people are ready to spend. If you don't give them a good venue, they won't spend at all. But if you give them a good venue, we have seen, we have a surprise. In fact, our ticketing partner was shocked to see, Siptan might add some point to that. The ticketing partner is pretty happy with the fact that we have sold the kind of inventory that we have. In three months. So much in advance. They have never seen a ticket before. Usually in IPL also, tickets of this number don't sell out so much in advance. We have made a good headway on that front. In fact, it's better than any other sporting event that Bukmah Show has ever done. So, how much inventory has sold already? We have about 45-30% already sold. So, it's still two months to the event. Yeah, two months is... And we all know all these events sell in the last month only. Last fortnight. And the hype gets real. Yeah, exactly. Because there's a build-up that has to happen. Now, every city we are going, we are seeing a spike. Because all the engagement that's happening in that city is getting amplified through PR, social media, locally. And because of that local amplification, we are seeing spikes in those cities. We saw a very big spike in Hyderabad, especially. I didn't tell you about that. Yesterday, it's this one, right? At the airport. Yeah, I told you. Pallavi was there with Rahe. He was talking in Gujarati. He said, yeah, yeah, racing. Motor Jeep, Arak Jeep car. I said, shit. So, this Fairstreets, what's your work? You've done this twice, right? In the middle, you were doing something else. And now you've come back to it? No, we have been with Fairstreets Sports. Earlier, Fairstreets was into investments. So, then we did some sports management. Softwares and sports management. Tournament management. Athlete identification products. We have made how to make sure that athletes are well identified in advance. Before they, I mean, right now, you know athlete wants to see a gold medal, but you don't know a struggle story. So, we made a platform for athlete identification. Then, from 19, we started working on this. And then we formed Fairstreets Sports as a presence entity. Not a partner in Fairstreets. Fairstreets was our first investment. As it goes by name. It's a fair game. So, you are one of the co-founders? Yes. And who are the others? Amit Chandel, Vygosh Sinha, Siddharth, Baldy. So, just a couple of questions. I mean, someone wanted to ask what was your talent? And, you know, learning from formula or whatever on the record you want to say. I mean, like, so, there's hardly anyone, any racer from India in particular, for in-motor sport. You can see names in formula. Like, in formula you list everyone. Two, I think. What about for a motor sport? So, how did you? I'll take you a step back. Motor VPs only race where they find talent from seven years. India champion is nine years old. And there is another guy who is 11 years old. So, motor VP identifies their talent from six to seven years. But point is, in India, we didn't have infrastructure in place. So, where people can come on board and start participating. But this year we are having wild card entry of motor VP riders. And we are also working on how to bring women in motor sport. There are lot of women riders. How to bring that? We are also trying to find out how to make this, how to bring motor sport, build motor sport in next two or three years. We want to convert motor sport to audience. As a mainstream motor sport. Motor sport right now is passion. We want to convert that to sport. Grassroot level. Grassroot level. If you have this type of infrastructure ready, safety is there, safety norms are being well followed. Then people will come and race. After this race, we are trying to conduct a safety week along with local authorities. And then we are also trying to conduct some regular sporting event here, motor sport. So that we get habit and culture in people to come and race on the track. And the track also stays intact? Track also stays intact. Track is always intact. You will be surprised to see we are not doing anything on the road. The road is fine. We are just making some security adjustment. And that's what we have to do with FIA and FIM. Together we have to bring them on board. Say that this should be FIA and FIM and the track. So that in future Formula 1 can also happen. So this year, we will come to know there will be lot of riders who are participating here. And India will see their first MotoGP rider as well. And for the Formula 1? And most, and if it's a female, don't get surprised. It's a plus. In terms of Formula 1, we saw, you were saying that in year 2, we saw declining in this order 3. I didn't came year 2. Because of entertainment, because of food. And that to sector 50. You know, forget about someone coming from Gurgaon or Mumbai or Kerala. I never came from sector 50. So that's my only goal. How someone from sector 50 should come. How someone from Gurgaon should come here. And why they should come every day. Why they should come every year. And then every year. And then ticket sales should not fall. Because first year people will come in Formula. But if I give them this type of infrastructure. And then, you know, with this infrastructure, lot of job will also get created. As per MotoGP, whenever they go in any province, they create 5000 jobs for the racing weekend itself. And they do a business of what, close to? 106. I'll give you those numbers. MotoGP I know. 106 million business they do. Euros. No, the money that gets generated. The money gets generated. It's the kind of economic benefit that MotoGP brings to the province that it's held in. It's a documented number. Indonesia, last year it happened. India report suggests about 1700 crores in Indian rupees. Economic benefits. And because Indonesia has third largest bike producer. We are single largest. We produce 18 million bikes a year. There are close to 200 million bikes on road now. With the 15 year data. MotoGP was shocked to see this data. Actually, this is another reason why we are very aggressive and bullish about. And even Dorma is very bullish about the prospect and potential of India as a market for MotoGP as a sport. Because Indians, we sell 18 million bikes a year. Out of that, approximately 1.2 million are in the 250cc plus category. Which means more than 1.2 million Indians are buying bikes for more than just transportation. They are buying bikes for thrill, adventure, sport, pleasure, whatever. So, that's a very big target market to set out to popularize and engage in the sport. So, what is Dorma's role in the commercial? How does it work? Dorma just gave us rights. Just the rights. Dorma is the commercial rights of this whole globe. And they have this local, every country has a local promoter to which they give the rights. Local promoters organize the racing back and forth. So, like we are for India, there will be 19 other promoters in 19 other countries. India is little different from other countries in terms of how Dorma will be functioning in India. So, like to attract the audience, you kind of have an idol, like a household name. If you see Valentino Rossi, you are like Michael Schumacher by Valentino Rossi. These kind of names attract the audience. Is Dorma going to help in that? Rossi has a team. Forget Rossi alone, he will come with a team to race. Rossi has an entire team called VR46 Mooney. So, now they race as part of MotoGP. And his riders are actually winning. And they go to Ducati. They are on Ducati and they are winning the race. How many teams will there be in total? On record? No, but there will be about 45 teams in total across categories. That's Moto3, Moto2 and MotoGP. I have given those numbers to you. The only difference now is that we are 20 races, not 21. Because Afghanistan is out. This is the same. And for the allied events, you will have separate tickets or separate tickets? No, same. And this year we are also doing a curtain reserve for MotoE. Which is very huge for India considering their train policy. Right now in India, there are very less manufacturers who produce e-bikes. We have e-scooters. I agree to that fact. Lot of e-scooters. But very less e-bikes. And MotoE bikes, even they run at speed of 275 kmph. And this will be first in Asia? First time they are coming out of Europe and doing a curtain reserve. So that from next year onwards, they can come and race. So this time they will come because batteries will come separate, bikes will come separate. They will come and assemble. So they will generate that type of business opportunities as well for the ancillary units. So that they can provide them some infrastructure support. That MotoE can race from next year. You were saying that India is different than say like Rotterdam. So how does that play? So as I said, like broadcaster. We sold the broadcasting right, not the Rotterdam. So they don't get anything from these bikes? They just get a... They have given us racing rights. That's all. We are selling their merchandise. They are not selling merchandise. And they get a fixed sum? They got only their racing fees. Nothing else. They are equally eager to come to India. That is the whole idea. Because either you come in the market like Formula 1, it was, it landed on wrong foot anyways. But you need to realize what you want from country. You want to earn money or you want to show that this is my model for first time. To this country. Whenever I enter into any developing nation or any Asian country. And this is how I become successful. Before to enter in any other market. So 10 years ago India was not ready for F1? I think so. I mean we... It's slightly different question. I mean we were not, our system was not ready. And F1, we didn't handshake properly. Probably the system was not studied properly. System was not studied properly. I think the thing is about homework. When F1 came, the people who were doing it, that's why I think they have done it well because of the homework. They have lived from their lives. They really went through the things to make it happen. For F1, it was more like when it happened they were thinking about it. But now, it's like, they are not thinking about it. For F1, it was more like when it happened they were thinking of it. Absolutely. So, and to sign a 7 page agreement, we took what, close to 3 months. And then to sign a bigger agreement, just an MOU, we took close to 3 months to sign 7 page MOU. To sign a larger agreement, long form agreement, took more than that. Took more? 6 months. 6 months. It was not just given to us, sign and go. We challenged everyone. We explained that if you are coming to India, you take that name that MotoGP came to India, it became so big. Right. Gurat Kohli alone has 300 million followers. No need to say. MotoGP has alone 300 million followers. So, it's a number game, it's passionate followers who are there. So, where did your investments come from? Was it an organic investment? Organic investment and we raised some investment. How much money you have raised? I will still, I am sorry, what was the question? How much money has been raised so far? Close to, close to, you can say around 10 million. 10 million. We have. Is it institutional capital you are also trying to? Yes. Institutional capital. Because the name is not all around. No, as before. We have a contribution and it was not a big one. I think I largely covered what I was talking about. Anything else that you might have got to touch on? In that respect, after successful competition of MotoGP, will you guys be involved in bringing F1 back? We are team. We will cross the bridge when we meet. We will cross the bridge when we meet. We have to explain them that there were some representative from F1, those who were talking to us. And we explained them the scenario. They have to understand. And their representatives were a little surprised to see that how we have pulled this off. Whenever they are ready, we are ready. I think we will answer a lot of questions what we do this year. It is a watchful year. But I think as an entity, we are a sports centric company. Opportunities are going to be there. So, keeping the interest alive in the 3 and 4 will determine the real success. For first year, we are sticking to the basics. Do the race properly. Make the track. And this itself is time consuming. The track is getting one shot at a night. 12th, now in flood lights, we are working. And rains. And rains. And whenever rain comes, we cover the construction. And then we start again. Then there is some water logging. We flush the water out. Then we start working again. Project management. And then we all have shifted from Noida to here. And we are here. So, Rohit. From Gurgaon every day and go in night and come back again at 10 o'clock. And now we are planning to stay in Greater Noida. So that we go out. When I am promoting, everyone should come here on the weekend. I should make that type of sacrifice. It's all a sweat equity and blood equity. So, Siptan goes to his house. He stays in Lucknow. He has shifted here. I don't know. Lucknow is probably closer than Noida. It's actually not closer but easier. It's an easy drive. You just get out of this expressway and you are back in Noida. I have tried not to get lost every time. But I keep getting lost every single time. Like it's never like you know the road and you just come and it takes you. You should come every day. I mean come. I think it's twice a week has happened already. It's a very important point since we are discussing how far it is. So, UP tourism is also setting up a kiosk here. And a health discounter. Because all the MotoGP guys, they will be close to 100 plus international media will come here. Where are they going to stay? Noida, Greater Noida. Arrangements are in process. And when they come here and when MotoGP team is here, there will be event after 4 o'clock. But if they want to go to Taj Mahal or Escon or to Banaras or to anywhere, there will be a help desk here. We will be taking them and carrying them and bringing them back. And G. Suman Vishwamitra is there. Yes, yes. We are working very close to UP government on tourism part as well. How to promote tourism. They have a philosophy called, now a department called ODOP. One district, one product. So, they will be setting up a small counter here to promote their products from the various districts. The rugs, the carpets. For sale. For sale also. So, it generates, helps economy a lot. There are poor people who are making those things and it gets unnoticed. So, how much revenue do you expect to make from the food and the other events within the main event? We will be probably able to tell you by next week's chat number. Three main kiosks. Three main zones for 30,000. So, you have a music event or something. That's part of your ticket? That's part of the ticket. That's why I said this year, I am not. So, anyone who comes here has right for entertainment. Has right for music festival rather not entertainment. Has right for music festival and the food festival which is happening here. You will get artists. We are spending on artists. We are spending on food festival just to make sure people get the experience. And not the traffic jam. And not the traffic jam. And then if they want to stay, we are partnering with local hotels. So, that they can also earn some money out of it. And so that next days people can come and go off the race. So, what is the perceived value? You were talking about Indonesia. In India, how much do you expect this? We should cross. Anywhere above 1000 crores is what we expect. 1000 crores is the benchmark. That's already a benchmark sent globally. And I am sure the kind of population that we cater to, we might end up even more. So, we can say it can have an economic impact of about 1000 crores. 1000 crores. So, 106 million euros is the average economic impact. There are smaller countries. There are larger countries. There are countries with very, very small population as well which pull down the average. And there are numbers like Indonesia which take the average up. So, we could anywhere be above average. Just to clarify that part, how is the taxation system affected in India? Like last time the government imposed 60% interest rate. So, that's the reason what Pushkar was mentioning. If you are going to earn money. Study was not done and it was structured in a wrong way. And nobody can, okay so let's not consider this on record. But just to explain to you, nobody can do business in India and not pay taxes, right? So, that's exactly what happened at that time. So, there was active business interest on ground which were happening from Formula 1. And they were not paying taxes. So, obviously they would end up in trouble. So, we don't want to quote all this but that's exactly what we don't want to do. For India for the first time MotoGP gave their broadcasting right to us so that we can. So, there is no business on ground that Dona has. It's everything that an Indian company does and then we pay taxes as per Indian law. As an Indian company does, as an Indian business does. And so as the, it's easier if we do it. We do it like any other Indian company. Good example. So, as the marketing lies. In Formula 1 who got the title sponsorship money? Formula 1. Yeah. You took money from him. And then they paid taxes. And got the naming right and got in your pocket. But now we have the title in our hand. Correct. So, will you take them for a spin if you want to? Yeah. You have some coffee? I have. Uncle Chips, my favourite. We will go with the four fingers for now. And then. I have now moved to 100. Lotus.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80133ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_segments = align_segments(\n",
    "        transcript[\"segments\"], transcript[\"language_code\"], audio_file, device)\n",
    "aligned_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ab4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "diarization_result = diarize(audio_file, hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f32f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "diarization_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ee3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_speakers(\n",
    "    diarization_result: Dict[str, Any], aligned_segments: Dict[str, Any]\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Assign speakers to each transcript segment based on the speaker diarization result.\n",
    "\n",
    "    Args:\n",
    "        diarization_result: Dictionary representing the diarized audio file, including the speaker embeddings and the number of speakers.\n",
    "        aligned_segments: Dictionary representing the aligned transcript segments.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries representing each segment of the transcript, including the start and end times, the\n",
    "        spoken text, and the speaker ID.\n",
    "    \"\"\"\n",
    "    result_segments = assign_word_speakers(\n",
    "        diarization_result, aligned_segments\n",
    "    )\n",
    "    results_segments_w_speakers: List[Dict[str, Any]] = []\n",
    "    for result_segment in result_segments['segments']:\n",
    "        try:\n",
    "            print(\"Okay Here\")\n",
    "            results_segments_w_speakers.append(\n",
    "                {\"start\": result_segment[\"start\"],\n",
    "                \"end\": result_segment[\"end\"],\n",
    "                \"text\": result_segment[\"text\"],\n",
    "                \"speaker\": result_segment[\"speaker\"]})\n",
    "        except KeyError:\n",
    "            print(\"ERROR Here\"\n",
    "            results_segments_w_speakers.append(\n",
    "                {\n",
    "                \"start\": result_segment[\"start\"],\n",
    "                \"end\": result_segment[\"end\"],\n",
    "                \"text\": result_segment[\"text\"],\n",
    "                \"speaker\": \" \"\n",
    "                })\n",
    "        \n",
    "    return results_segments_w_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e61ab738",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'segments': [{'start': 0.122, 'end': 0.994, 'text': \" What's your background?\", 'words': [{'word': \"What's\", 'start': 0.122, 'end': 0.264, 'score': 0.483}, {'word': 'your', 'start': 0.284, 'end': 0.507, 'score': 0.413, 'speaker': 'SPEAKER_00'}, {'word': 'background?', 'start': 0.629, 'end': 0.974, 'score': 0.52, 'speaker': 'SPEAKER_00'}], 'speaker': 'SPEAKER_00'}, {'start': 0.994, 'end': 1.298, 'text': 'Like, give me...', 'words': [{'word': 'Like,', 'start': 0.994, 'end': 1.095, 'score': 0.173, 'speaker': 'SPEAKER_00'}, {'word': 'give', 'start': 1.115, 'end': 1.217, 'score': 0.341, 'speaker': 'SPEAKER_00'}, {'word': 'me...', 'start': 1.237, 'end': 1.298, 'score': 0.607, 'speaker': 'SPEAKER_00'}], 'speaker': 'SPEAKER_00'}, {'start': 1.581, 'end': 6.54, 'text': ' Yeah, I mean, yeah, complete lower middle class background in a place in Mumbai called Grant Road.', 'words': [{'word': 'Yeah,', 'start': 1.581, 'end': 1.801, 'score': 0.576, 'speaker': 'SPEAKER_00'}, {'word': 'I', 'start': 1.882, 'end': 1.922, 'score': 0.979, 'speaker': 'SPEAKER_00'}, {'word': 'mean,', 'start': 1.962, 'end': 2.103, 'score': 0.803, 'speaker': 'SPEAKER_00'}, {'word': 'yeah,', 'start': 2.203, 'end': 2.504, 'score': 0.521, 'speaker': 'SPEAKER_00'}, {'word': 'complete', 'start': 2.866, 'end': 3.187, 'score': 0.989, 'speaker': 'SPEAKER_00'}, {'word': 'lower', 'start': 3.227, 'end': 3.448, 'score': 0.821, 'speaker': 'SPEAKER_00'}, {'word': 'middle', 'start': 3.488, 'end': 3.689, 'score': 0.956, 'speaker': 'SPEAKER_00'}, {'word': 'class', 'start': 3.709, 'end': 3.97, 'score': 0.864, 'speaker': 'SPEAKER_00'}, {'word': 'background', 'start': 4.03, 'end': 4.472, 'score': 0.95, 'speaker': 'SPEAKER_00'}, {'word': 'in', 'start': 4.532, 'end': 4.632, 'score': 0.741, 'speaker': 'SPEAKER_00'}, {'word': 'a', 'start': 4.653, 'end': 4.693, 'score': 0.481, 'speaker': 'SPEAKER_00'}, {'word': 'place', 'start': 4.753, 'end': 4.974, 'score': 0.898, 'speaker': 'SPEAKER_00'}, {'word': 'in', 'start': 4.994, 'end': 5.034, 'score': 0.017, 'speaker': 'SPEAKER_00'}, {'word': 'Mumbai', 'start': 5.074, 'end': 5.355, 'score': 0.747, 'speaker': 'SPEAKER_00'}, {'word': 'called', 'start': 5.375, 'end': 5.998, 'score': 0.393, 'speaker': 'SPEAKER_00'}, {'word': 'Grant', 'start': 6.058, 'end': 6.319, 'score': 0.921, 'speaker': 'SPEAKER_00'}, {'word': 'Road.', 'start': 6.379, 'end': 6.54, 'score': 0.783, 'speaker': 'SPEAKER_00'}], 'speaker': 'SPEAKER_00'}, {'start': 6.881, 'end': 8.94, 'text': ' I do remember we had a large joint family.', 'words': [{'word': 'I', 'start': 6.881, 'end': 6.942, 'score': 0.951, 'speaker': 'SPEAKER_00'}, {'word': 'do', 'start': 6.982, 'end': 7.103, 'score': 0.767, 'speaker': 'SPEAKER_00'}, {'word': 'remember', 'start': 7.144, 'end': 7.487, 'score': 0.913, 'speaker': 'SPEAKER_00'}, {'word': 'we', 'start': 7.527, 'end': 7.608, 'score': 0.863, 'speaker': 'SPEAKER_00'}, {'word': 'had', 'start': 7.628, 'end': 7.729, 'score': 0.433, 'speaker': 'SPEAKER_00'}, {'word': 'a', 'start': 7.749, 'end': 7.81, 'score': 0.074, 'speaker': 'SPEAKER_00'}, {'word': 'large', 'start': 7.991, 'end': 8.234, 'score': 0.678, 'speaker': 'SPEAKER_00'}, {'word': 'joint', 'start': 8.274, 'end': 8.556, 'score': 0.608, 'speaker': 'SPEAKER_00'}, {'word': 'family.', 'start': 8.617, 'end': 8.94, 'score': 0.927, 'speaker': 'SPEAKER_00'}], 'speaker': 'SPEAKER_00'}, {'start': 9.102, 'end': 10.357, 'text': ' There was no private bedroom.', 'words': [{'word': 'There', 'start': 9.102, 'end': 9.223, 'score': 0.701, 'speaker': 'SPEAKER_00'}, {'word': 'was', 'start': 9.244, 'end': 9.304, 'score': 0.991, 'speaker': 'SPEAKER_00'}, {'word': 'no', 'start': 9.345, 'end': 9.466, 'score': 0.871, 'speaker': 'SPEAKER_00'}, {'word': 'private', 'start': 9.527, 'end': 9.892, 'score': 0.875, 'speaker': 'SPEAKER_00'}, {'word': 'bedroom.', 'start': 9.993, 'end': 10.357, 'score': 0.955, 'speaker': 'SPEAKER_00'}], 'speaker': 'SPEAKER_00'}, {'start': 10.701, 'end': 13.832, 'text': ' The toilet was at the end of the door and I spent my first 17 years.', 'words': [{'word': 'The', 'start': 10.701, 'end': 10.841, 'score': 0.749, 'speaker': 'SPEAKER_00'}, {'word': 'toilet', 'start': 10.941, 'end': 11.263, 'score': 0.804, 'speaker': 'SPEAKER_00'}, {'word': 'was', 'start': 11.283, 'end': 11.403, 'score': 0.7, 'speaker': 'SPEAKER_00'}, {'word': 'at', 'start': 11.463, 'end': 11.524, 'score': 0.752, 'speaker': 'SPEAKER_00'}, {'word': 'the', 'start': 11.544, 'end': 11.624, 'score': 0.888, 'speaker': 'SPEAKER_00'}, {'word': 'end', 'start': 11.664, 'end': 11.764, 'score': 0.919, 'speaker': 'SPEAKER_00'}, {'word': 'of', 'start': 11.805, 'end': 11.845, 'score': 0.998, 'speaker': 'SPEAKER_00'}, {'word': 'the', 'start': 11.885, 'end': 11.945, 'score': 0.994, 'speaker': 'SPEAKER_00'}, {'word': 'door', 'start': 11.985, 'end': 12.146, 'score': 0.866, 'speaker': 'SPEAKER_00'}, {'word': 'and', 'start': 12.166, 'end': 12.246, 'score': 0.831, 'speaker': 'SPEAKER_00'}, {'word': 'I', 'start': 12.266, 'end': 12.306, 'score': 0.492, 'speaker': 'SPEAKER_00'}, {'word': 'spent', 'start': 12.367, 'end': 12.567, 'score': 0.803, 'speaker': 'SPEAKER_00'}, {'word': 'my', 'start': 12.608, 'end': 12.708, 'score': 0.859, 'speaker': 'SPEAKER_00'}, {'word': 'first', 'start': 12.748, 'end': 12.929, 'score': 0.908, 'speaker': 'SPEAKER_00'}, {'word': '17'}, {'word': 'years.', 'start': 13.39, 'end': 13.631, 'score': 0.849, 'speaker': 'SPEAKER_00'}], 'speaker': 'SPEAKER_00'}, {'start': 13.832, 'end': 15.98, 'text': 'Incredible grounding in those days.', 'words': [{'word': 'Incredible', 'start': 13.832, 'end': 14.434, 'score': 0.878, 'speaker': 'SPEAKER_00'}, {'word': 'grounding', 'start': 14.655, 'end': 15.117, 'score': 0.89, 'speaker': 'SPEAKER_00'}, {'word': 'in', 'start': 15.358, 'end': 15.418, 'score': 0.982, 'speaker': 'SPEAKER_00'}, {'word': 'those', 'start': 15.458, 'end': 15.679, 'score': 0.871, 'speaker': 'SPEAKER_00'}, {'word': 'days.', 'start': 15.719, 'end': 15.98, 'score': 0.834, 'speaker': 'SPEAKER_00'}], 'speaker': 'SPEAKER_00'}, {'start': 16.3, 'end': 22.38, 'text': ' You know, there was a lovely cafe 786 on the ground floor which served the best biryani in Grant Road and the best jalebis.', 'words': [{'word': 'You', 'start': 16.3, 'end': 16.461, 'score': 0.592, 'speaker': 'SPEAKER_00'}, {'word': 'know,', 'start': 16.541, 'end': 16.922, 'score': 0.55, 'speaker': 'SPEAKER_00'}, {'word': 'there', 'start': 17.003, 'end': 17.123, 'score': 0.992, 'speaker': 'SPEAKER_00'}, {'word': 'was', 'start': 17.143, 'end': 17.223, 'score': 0.833, 'speaker': 'SPEAKER_00'}, {'word': 'a', 'start': 17.243, 'end': 17.264, 'score': 0.994, 'speaker': 'SPEAKER_00'}, {'word': 'lovely', 'start': 17.304, 'end': 17.585, 'score': 0.937, 'speaker': 'SPEAKER_00'}, {'word': 'cafe', 'start': 17.725, 'end': 18.508, 'score': 0.677, 'speaker': 'SPEAKER_00'}, {'word': '786'}, {'word': 'on', 'start': 18.849, 'end': 18.909, 'score': 0.911, 'speaker': 'SPEAKER_00'}, {'word': 'the', 'start': 18.949, 'end': 19.009, 'score': 0.998, 'speaker': 'SPEAKER_00'}, {'word': 'ground', 'start': 19.029, 'end': 19.27, 'score': 0.874, 'speaker': 'SPEAKER_00'}, {'word': 'floor', 'start': 19.33, 'end': 19.591, 'score': 0.892, 'speaker': 'SPEAKER_00'}, {'word': 'which', 'start': 19.631, 'end': 19.792, 'score': 0.803, 'speaker': 'SPEAKER_00'}, {'word': 'served', 'start': 19.872, 'end': 20.113, 'score': 0.891, 'speaker': 'SPEAKER_00'}, {'word': 'the', 'start': 20.133, 'end': 20.193, 'score': 0.998, 'speaker': 'SPEAKER_00'}, {'word': 'best', 'start': 20.233, 'end': 20.394, 'score': 0.872, 'speaker': 'SPEAKER_00'}, {'word': 'biryani', 'start': 20.454, 'end': 20.855, 'score': 0.883, 'speaker': 'SPEAKER_00'}, {'word': 'in', 'start': 20.875, 'end': 20.975, 'score': 0.711, 'speaker': 'SPEAKER_00'}, {'word': 'Grant', 'start': 21.016, 'end': 21.256, 'score': 0.75, 'speaker': 'SPEAKER_00'}, {'word': 'Road', 'start': 21.317, 'end': 21.557, 'score': 0.659, 'speaker': 'SPEAKER_00'}, {'word': 'and', 'start': 21.617, 'end': 21.678, 'score': 0.546, 'speaker': 'SPEAKER_00'}, {'word': 'the', 'start': 21.698, 'end': 21.758, 'score': 0.696, 'speaker': 'SPEAKER_00'}, {'word': 'best', 'start': 21.798, 'end': 21.959, 'score': 0.892, 'speaker': 'SPEAKER_00'}, {'word': 'jalebis.', 'start': 21.999, 'end': 22.38, 'score': 0.729, 'speaker': 'SPEAKER_00'}], 'speaker': 'SPEAKER_00'}, {'start': 22.643, 'end': 22.914, 'text': ' Okay.', 'words': [{'word': 'Okay.', 'start': 22.643, 'end': 22.914, 'score': 0.495, 'speaker': 'SPEAKER_00'}], 'speaker': 'SPEAKER_00'}, {'start': 23.141, 'end': 25.74, 'text': ' My two aunts and my mom used to teach the piano.', 'words': [{'word': 'My', 'start': 23.141, 'end': 23.403, 'score': 0.962, 'speaker': 'SPEAKER_00'}, {'word': 'two', 'start': 23.523, 'end': 23.685, 'score': 0.871, 'speaker': 'SPEAKER_00'}, {'word': 'aunts', 'start': 23.826, 'end': 24.067, 'score': 0.656, 'speaker': 'SPEAKER_00'}, {'word': 'and', 'start': 24.209, 'end': 24.289, 'score': 0.97, 'speaker': 'SPEAKER_00'}, {'word': 'my', 'start': 24.309, 'end': 24.43, 'score': 0.98, 'speaker': 'SPEAKER_00'}, {'word': 'mom', 'start': 24.47, 'end': 24.712, 'score': 0.768, 'speaker': 'SPEAKER_00'}, {'word': 'used', 'start': 24.833, 'end': 24.954, 'score': 0.874, 'speaker': 'SPEAKER_00'}, {'word': 'to', 'start': 24.994, 'end': 25.035, 'score': 0.988, 'speaker': 'SPEAKER_00'}, {'word': 'teach', 'start': 25.095, 'end': 25.297, 'score': 0.572, 'speaker': 'SPEAKER_00'}, {'word': 'the', 'start': 25.337, 'end': 25.417, 'score': 0.852, 'speaker': 'SPEAKER_00'}, {'word': 'piano.', 'start': 25.438, 'end': 25.74, 'score': 0.951, 'speaker': 'SPEAKER_00'}], 'speaker': 'SPEAKER_00'}, {'start': 26.061, 'end': 30.699, 'text': ' So I think all my first few girlfriends were all piano students that would come there.', 'words': [{'word': 'So', 'start': 26.061, 'end': 26.101, 'score': 0.002, 'speaker': 'SPEAKER_00'}, {'word': 'I', 'start': 26.121, 'end': 26.201, 'score': 0.516, 'speaker': 'SPEAKER_00'}, {'word': 'think', 'start': 26.221, 'end': 26.362, 'score': 0.475, 'speaker': 'SPEAKER_00'}, {'word': 'all', 'start': 26.462, 'end': 26.603, 'score': 0.783, 'speaker': 'SPEAKER_00'}, {'word': 'my', 'start': 26.623, 'end': 26.743, 'score': 0.832, 'speaker': 'SPEAKER_00'}, {'word': 'first', 'start': 26.784, 'end': 27.045, 'score': 0.75, 'speaker': 'SPEAKER_00'}, {'word': 'few', 'start': 27.145, 'end': 27.346, 'score': 0.739, 'speaker': 'SPEAKER_00'}, {'word': 'girlfriends', 'start': 27.446, 'end': 27.888, 'score': 0.786, 'speaker': 'SPEAKER_00'}, {'word': 'were', 'start': 27.928, 'end': 28.069, 'score': 0.985, 'speaker': 'SPEAKER_00'}, {'word': 'all', 'start': 28.149, 'end': 28.269, 'score': 0.953, 'speaker': 'SPEAKER_00'}, {'word': 'piano', 'start': 28.289, 'end': 28.791, 'score': 0.665, 'speaker': 'SPEAKER_00'}, {'word': 'students', 'start': 28.811, 'end': 29.153, 'score': 0.363, 'speaker': 'SPEAKER_00'}, {'word': 'that', 'start': 29.173, 'end': 29.333, 'score': 0.402, 'speaker': 'SPEAKER_00'}, {'word': 'would', 'start': 29.374, 'end': 29.615, 'score': 0.486, 'speaker': 'SPEAKER_00'}, {'word': 'come', 'start': 29.655, 'end': 30.478, 'score': 0.623, 'speaker': 'SPEAKER_00'}, {'word': 'there.', 'start': 30.498, 'end': 30.699, 'score': 0.505, 'speaker': 'SPEAKER_00'}], 'speaker': 'SPEAKER_00'}, {'start': 31.841, 'end': 32.954, 'text': ' Did you learn to impress them?', 'words': [{'word': 'Did', 'start': 31.841, 'end': 31.962, 'score': 0.389, 'speaker': 'SPEAKER_00'}, {'word': 'you', 'start': 32.003, 'end': 32.104, 'score': 0.842, 'speaker': 'SPEAKER_00'}, {'word': 'learn', 'start': 32.246, 'end': 32.489, 'score': 0.464, 'speaker': 'SPEAKER_00'}, {'word': 'to', 'start': 32.509, 'end': 32.59, 'score': 0.809, 'speaker': 'SPEAKER_00'}, {'word': 'impress', 'start': 32.61, 'end': 32.853, 'score': 0.28, 'speaker': 'SPEAKER_00'}, {'word': 'them?', 'start': 32.873, 'end': 32.954, 'score': 0.426, 'speaker': 'SPEAKER_00'}], 'speaker': 'SPEAKER_00'}, {'start': 33.54, 'end': 38.24, 'text': ' Yes, I learned how to play the piano in the process, but that is compliments to my mom and my aunts.', 'words': [{'word': 'Yes,', 'start': 33.54, 'end': 33.741, 'score': 0.953, 'speaker': 'SPEAKER_00'}, {'word': 'I', 'start': 34.123, 'end': 34.203, 'score': 0.852, 'speaker': 'SPEAKER_00'}, {'word': 'learned', 'start': 34.223, 'end': 34.444, 'score': 0.775, 'speaker': 'SPEAKER_00'}, {'word': 'how', 'start': 34.464, 'end': 34.545, 'score': 0.99, 'speaker': 'SPEAKER_00'}, {'word': 'to', 'start': 34.585, 'end': 34.625, 'score': 0.998, 'speaker': 'SPEAKER_00'}, {'word': 'play', 'start': 34.665, 'end': 34.846, 'score': 0.73, 'speaker': 'SPEAKER_00'}, {'word': 'the', 'start': 34.906, 'end': 34.986, 'score': 0.83, 'speaker': 'SPEAKER_00'}, {'word': 'piano', 'start': 35.227, 'end': 35.589, 'score': 0.952, 'speaker': 'SPEAKER_00'}, {'word': 'in', 'start': 35.75, 'end': 35.83, 'score': 0.832, 'speaker': 'SPEAKER_00'}, {'word': 'the', 'start': 35.85, 'end': 35.93, 'score': 0.824, 'speaker': 'SPEAKER_00'}, {'word': 'process,', 'start': 35.971, 'end': 36.392, 'score': 0.862, 'speaker': 'SPEAKER_00'}, {'word': 'but', 'start': 36.412, 'end': 36.533, 'score': 0.877, 'speaker': 'SPEAKER_00'}, {'word': 'that', 'start': 36.573, 'end': 36.714, 'score': 0.898, 'speaker': 'SPEAKER_00'}, {'word': 'is', 'start': 36.774, 'end': 36.834, 'score': 0.758, 'speaker': 'SPEAKER_00'}, {'word': 'compliments', 'start': 36.874, 'end': 37.336, 'score': 0.872, 'speaker': 'SPEAKER_00'}, {'word': 'to', 'start': 37.376, 'end': 37.437, 'score': 0.811, 'speaker': 'SPEAKER_00'}, {'word': 'my', 'start': 37.477, 'end': 37.577, 'score': 0.98, 'speaker': 'SPEAKER_00'}, {'word': 'mom', 'start': 37.617, 'end': 37.798, 'score': 0.814, 'speaker': 'SPEAKER_00'}, {'word': 'and', 'start': 37.818, 'end': 37.899, 'score': 0.41, 'speaker': 'SPEAKER_00'}, {'word': 'my', 'start': 37.919, 'end': 38.059, 'score': 0.98, 'speaker': 'SPEAKER_00'}, {'word': 'aunts.', 'start': 38.14, 'end': 38.24, 'score': 0.026, 'speaker': 'SPEAKER_00'}], 'speaker': 'SPEAKER_00'}, {'start': 39.864, 'end': 44.44, 'text': \" Not the girlfriends, but very very fond memories and that's why I meant that you get grounded.\", 'words': [{'word': 'Not', 'start': 39.864, 'end': 40.025, 'score': 0.886, 'speaker': 'SPEAKER_00'}, {'word': 'the', 'start': 40.045, 'end': 40.125, 'score': 0.92, 'speaker': 'SPEAKER_00'}, {'word': 'girlfriends,', 'start': 40.165, 'end': 40.667, 'score': 0.561, 'speaker': 'SPEAKER_00'}, {'word': 'but', 'start': 40.747, 'end': 40.868, 'score': 0.992, 'speaker': 'SPEAKER_00'}, {'word': 'very', 'start': 40.948, 'end': 41.149, 'score': 0.865, 'speaker': 'SPEAKER_00'}, {'word': 'very', 'start': 41.189, 'end': 41.389, 'score': 0.77, 'speaker': 'SPEAKER_00'}, {'word': 'fond', 'start': 41.45, 'end': 41.67, 'score': 0.861, 'speaker': 'SPEAKER_00'}, {'word': 'memories', 'start': 41.731, 'end': 42.132, 'score': 0.879, 'speaker': 'SPEAKER_00'}, {'word': 'and', 'start': 42.373, 'end': 42.453, 'score': 0.958, 'speaker': 'SPEAKER_00'}, {'word': \"that's\", 'start': 42.513, 'end': 42.694, 'score': 0.93, 'speaker': 'SPEAKER_00'}, {'word': 'why', 'start': 42.734, 'end': 42.854, 'score': 0.892, 'speaker': 'SPEAKER_00'}, {'word': 'I', 'start': 42.895, 'end': 42.955, 'score': 0.344, 'speaker': 'SPEAKER_00'}, {'word': 'meant', 'start': 43.015, 'end': 43.236, 'score': 0.673, 'speaker': 'SPEAKER_00'}, {'word': 'that', 'start': 43.677, 'end': 43.798, 'score': 0.916, 'speaker': 'SPEAKER_00'}, {'word': 'you', 'start': 43.838, 'end': 43.938, 'score': 0.945, 'speaker': 'SPEAKER_00'}, {'word': 'get', 'start': 43.978, 'end': 44.099, 'score': 0.908, 'speaker': 'SPEAKER_00'}, {'word': 'grounded.', 'start': 44.139, 'end': 44.44, 'score': 0.749, 'speaker': 'SPEAKER_00'}], 'speaker': 'SPEAKER_00'}, {'start': 44.66, 'end': 51.44, 'text': \" You know, then your expectation on life is everything is up there and I think many of the times when I've been set back\", 'words': [{'word': 'You', 'start': 44.66, 'end': 44.72, 'score': 0.996, 'speaker': 'SPEAKER_00'}, {'word': 'know,', 'start': 44.741, 'end': 44.861, 'score': 0.939, 'speaker': 'SPEAKER_00'}, {'word': 'then', 'start': 44.901, 'end': 45.021, 'score': 0.801, 'speaker': 'SPEAKER_00'}, {'word': 'your', 'start': 45.041, 'end': 45.202, 'score': 0.879, 'speaker': 'SPEAKER_00'}, {'word': 'expectation', 'start': 45.282, 'end': 45.924, 'score': 0.94, 'speaker': 'SPEAKER_00'}, {'word': 'on', 'start': 45.984, 'end': 46.104, 'score': 0.622, 'speaker': 'SPEAKER_00'}, {'word': 'life', 'start': 46.185, 'end': 46.466, 'score': 0.97, 'speaker': 'SPEAKER_00'}, {'word': 'is', 'start': 46.626, 'end': 46.686, 'score': 0.75, 'speaker': 'SPEAKER_00'}, {'word': 'everything', 'start': 46.746, 'end': 46.987, 'score': 0.967, 'speaker': 'SPEAKER_00'}, {'word': 'is', 'start': 47.047, 'end': 47.168, 'score': 0.673, 'speaker': 'SPEAKER_00'}, {'word': 'up', 'start': 47.809, 'end': 47.91, 'score': 0.852, 'speaker': 'SPEAKER_00'}, {'word': 'there', 'start': 47.99, 'end': 48.251, 'score': 0.762, 'speaker': 'SPEAKER_00'}, {'word': 'and', 'start': 48.552, 'end': 48.632, 'score': 0.984, 'speaker': 'SPEAKER_00'}, {'word': 'I', 'start': 48.672, 'end': 48.732, 'score': 0.913, 'speaker': 'SPEAKER_00'}, {'word': 'think', 'start': 48.772, 'end': 48.953, 'score': 0.701, 'speaker': 'SPEAKER_00'}, {'word': 'many', 'start': 49.575, 'end': 49.795, 'score': 0.863, 'speaker': 'SPEAKER_00'}, {'word': 'of', 'start': 49.815, 'end': 49.875, 'score': 0.748, 'speaker': 'SPEAKER_00'}, {'word': 'the', 'start': 49.916, 'end': 49.996, 'score': 0.975, 'speaker': 'SPEAKER_00'}, {'word': 'times', 'start': 50.036, 'end': 50.297, 'score': 0.812, 'speaker': 'SPEAKER_00'}, {'word': 'when', 'start': 50.337, 'end': 50.437, 'score': 0.999, 'speaker': 'SPEAKER_00'}, {'word': \"I've\", 'start': 50.457, 'end': 50.618, 'score': 0.642, 'speaker': 'SPEAKER_00'}, {'word': 'been', 'start': 50.638, 'end': 50.798, 'score': 0.842, 'speaker': 'SPEAKER_00'}, {'word': 'set', 'start': 50.858, 'end': 51.079, 'score': 0.855, 'speaker': 'SPEAKER_00'}, {'word': 'back', 'start': 51.219, 'end': 51.44, 'score': 0.264, 'speaker': 'SPEAKER_00'}], 'speaker': 'SPEAKER_00'}, {'start': 52.301, 'end': 55.18, 'text': ' my introspection was now how worse can it get?', 'words': [{'word': 'my', 'start': 52.301, 'end': 52.482, 'score': 0.946, 'speaker': 'SPEAKER_00'}, {'word': 'introspection', 'start': 52.764, 'end': 53.388, 'score': 0.92, 'speaker': 'SPEAKER_00'}, {'word': 'was', 'start': 53.428, 'end': 53.63, 'score': 0.877, 'speaker': 'SPEAKER_00'}, {'word': 'now', 'start': 53.75, 'end': 53.912, 'score': 0.917, 'speaker': 'SPEAKER_00'}, {'word': 'how', 'start': 53.972, 'end': 54.193, 'score': 0.915, 'speaker': 'SPEAKER_00'}, {'word': 'worse', 'start': 54.334, 'end': 54.656, 'score': 0.887, 'speaker': 'SPEAKER_00'}, {'word': 'can', 'start': 54.697, 'end': 54.878, 'score': 0.833, 'speaker': 'SPEAKER_00'}, {'word': 'it', 'start': 54.898, 'end': 54.938, 'score': 0.702, 'speaker': 'SPEAKER_00'}, {'word': 'get?', 'start': 55.079, 'end': 55.18, 'score': 0.222, 'speaker': 'SPEAKER_00'}], 'speaker': 'SPEAKER_00'}, {'start': 55.76, 'end': 55.953, 'text': ' You', 'words': [{'word': 'You', 'start': 55.76, 'end': 55.953, 'score': 0.007}]}], 'word_segments': [{'word': \"What's\", 'start': 0.122, 'end': 0.264, 'score': 0.483}, {'word': 'your', 'start': 0.284, 'end': 0.507, 'score': 0.413, 'speaker': 'SPEAKER_00'}, {'word': 'background?', 'start': 0.629, 'end': 0.974, 'score': 0.52, 'speaker': 'SPEAKER_00'}, {'word': 'Like,', 'start': 0.994, 'end': 1.095, 'score': 0.173, 'speaker': 'SPEAKER_00'}, {'word': 'give', 'start': 1.115, 'end': 1.217, 'score': 0.341, 'speaker': 'SPEAKER_00'}, {'word': 'me...', 'start': 1.237, 'end': 1.298, 'score': 0.607, 'speaker': 'SPEAKER_00'}, {'word': 'Yeah,', 'start': 1.581, 'end': 1.801, 'score': 0.576, 'speaker': 'SPEAKER_00'}, {'word': 'I', 'start': 1.882, 'end': 1.922, 'score': 0.979, 'speaker': 'SPEAKER_00'}, {'word': 'mean,', 'start': 1.962, 'end': 2.103, 'score': 0.803, 'speaker': 'SPEAKER_00'}, {'word': 'yeah,', 'start': 2.203, 'end': 2.504, 'score': 0.521, 'speaker': 'SPEAKER_00'}, {'word': 'complete', 'start': 2.866, 'end': 3.187, 'score': 0.989, 'speaker': 'SPEAKER_00'}, {'word': 'lower', 'start': 3.227, 'end': 3.448, 'score': 0.821, 'speaker': 'SPEAKER_00'}, {'word': 'middle', 'start': 3.488, 'end': 3.689, 'score': 0.956, 'speaker': 'SPEAKER_00'}, {'word': 'class', 'start': 3.709, 'end': 3.97, 'score': 0.864, 'speaker': 'SPEAKER_00'}, {'word': 'background', 'start': 4.03, 'end': 4.472, 'score': 0.95, 'speaker': 'SPEAKER_00'}, {'word': 'in', 'start': 4.532, 'end': 4.632, 'score': 0.741, 'speaker': 'SPEAKER_00'}, {'word': 'a', 'start': 4.653, 'end': 4.693, 'score': 0.481, 'speaker': 'SPEAKER_00'}, {'word': 'place', 'start': 4.753, 'end': 4.974, 'score': 0.898, 'speaker': 'SPEAKER_00'}, {'word': 'in', 'start': 4.994, 'end': 5.034, 'score': 0.017, 'speaker': 'SPEAKER_00'}, {'word': 'Mumbai', 'start': 5.074, 'end': 5.355, 'score': 0.747, 'speaker': 'SPEAKER_00'}, {'word': 'called', 'start': 5.375, 'end': 5.998, 'score': 0.393, 'speaker': 'SPEAKER_00'}, {'word': 'Grant', 'start': 6.058, 'end': 6.319, 'score': 0.921, 'speaker': 'SPEAKER_00'}, {'word': 'Road.', 'start': 6.379, 'end': 6.54, 'score': 0.783, 'speaker': 'SPEAKER_00'}, {'word': 'I', 'start': 6.881, 'end': 6.942, 'score': 0.951, 'speaker': 'SPEAKER_00'}, {'word': 'do', 'start': 6.982, 'end': 7.103, 'score': 0.767, 'speaker': 'SPEAKER_00'}, {'word': 'remember', 'start': 7.144, 'end': 7.487, 'score': 0.913, 'speaker': 'SPEAKER_00'}, {'word': 'we', 'start': 7.527, 'end': 7.608, 'score': 0.863, 'speaker': 'SPEAKER_00'}, {'word': 'had', 'start': 7.628, 'end': 7.729, 'score': 0.433, 'speaker': 'SPEAKER_00'}, {'word': 'a', 'start': 7.749, 'end': 7.81, 'score': 0.074, 'speaker': 'SPEAKER_00'}, {'word': 'large', 'start': 7.991, 'end': 8.234, 'score': 0.678, 'speaker': 'SPEAKER_00'}, {'word': 'joint', 'start': 8.274, 'end': 8.556, 'score': 0.608, 'speaker': 'SPEAKER_00'}, {'word': 'family.', 'start': 8.617, 'end': 8.94, 'score': 0.927, 'speaker': 'SPEAKER_00'}, {'word': 'There', 'start': 9.102, 'end': 9.223, 'score': 0.701, 'speaker': 'SPEAKER_00'}, {'word': 'was', 'start': 9.244, 'end': 9.304, 'score': 0.991, 'speaker': 'SPEAKER_00'}, {'word': 'no', 'start': 9.345, 'end': 9.466, 'score': 0.871, 'speaker': 'SPEAKER_00'}, {'word': 'private', 'start': 9.527, 'end': 9.892, 'score': 0.875, 'speaker': 'SPEAKER_00'}, {'word': 'bedroom.', 'start': 9.993, 'end': 10.357, 'score': 0.955, 'speaker': 'SPEAKER_00'}, {'word': 'The', 'start': 10.701, 'end': 10.841, 'score': 0.749, 'speaker': 'SPEAKER_00'}, {'word': 'toilet', 'start': 10.941, 'end': 11.263, 'score': 0.804, 'speaker': 'SPEAKER_00'}, {'word': 'was', 'start': 11.283, 'end': 11.403, 'score': 0.7, 'speaker': 'SPEAKER_00'}, {'word': 'at', 'start': 11.463, 'end': 11.524, 'score': 0.752, 'speaker': 'SPEAKER_00'}, {'word': 'the', 'start': 11.544, 'end': 11.624, 'score': 0.888, 'speaker': 'SPEAKER_00'}, {'word': 'end', 'start': 11.664, 'end': 11.764, 'score': 0.919, 'speaker': 'SPEAKER_00'}, {'word': 'of', 'start': 11.805, 'end': 11.845, 'score': 0.998, 'speaker': 'SPEAKER_00'}, {'word': 'the', 'start': 11.885, 'end': 11.945, 'score': 0.994, 'speaker': 'SPEAKER_00'}, {'word': 'door', 'start': 11.985, 'end': 12.146, 'score': 0.866, 'speaker': 'SPEAKER_00'}, {'word': 'and', 'start': 12.166, 'end': 12.246, 'score': 0.831, 'speaker': 'SPEAKER_00'}, {'word': 'I', 'start': 12.266, 'end': 12.306, 'score': 0.492, 'speaker': 'SPEAKER_00'}, {'word': 'spent', 'start': 12.367, 'end': 12.567, 'score': 0.803, 'speaker': 'SPEAKER_00'}, {'word': 'my', 'start': 12.608, 'end': 12.708, 'score': 0.859, 'speaker': 'SPEAKER_00'}, {'word': 'first', 'start': 12.748, 'end': 12.929, 'score': 0.908, 'speaker': 'SPEAKER_00'}, {'word': '17'}, {'word': 'years.', 'start': 13.39, 'end': 13.631, 'score': 0.849, 'speaker': 'SPEAKER_00'}, {'word': 'Incredible', 'start': 13.832, 'end': 14.434, 'score': 0.878, 'speaker': 'SPEAKER_00'}, {'word': 'grounding', 'start': 14.655, 'end': 15.117, 'score': 0.89, 'speaker': 'SPEAKER_00'}, {'word': 'in', 'start': 15.358, 'end': 15.418, 'score': 0.982, 'speaker': 'SPEAKER_00'}, {'word': 'those', 'start': 15.458, 'end': 15.679, 'score': 0.871, 'speaker': 'SPEAKER_00'}, {'word': 'days.', 'start': 15.719, 'end': 15.98, 'score': 0.834, 'speaker': 'SPEAKER_00'}, {'word': 'You', 'start': 16.3, 'end': 16.461, 'score': 0.592, 'speaker': 'SPEAKER_00'}, {'word': 'know,', 'start': 16.541, 'end': 16.922, 'score': 0.55, 'speaker': 'SPEAKER_00'}, {'word': 'there', 'start': 17.003, 'end': 17.123, 'score': 0.992, 'speaker': 'SPEAKER_00'}, {'word': 'was', 'start': 17.143, 'end': 17.223, 'score': 0.833, 'speaker': 'SPEAKER_00'}, {'word': 'a', 'start': 17.243, 'end': 17.264, 'score': 0.994, 'speaker': 'SPEAKER_00'}, {'word': 'lovely', 'start': 17.304, 'end': 17.585, 'score': 0.937, 'speaker': 'SPEAKER_00'}, {'word': 'cafe', 'start': 17.725, 'end': 18.508, 'score': 0.677, 'speaker': 'SPEAKER_00'}, {'word': '786'}, {'word': 'on', 'start': 18.849, 'end': 18.909, 'score': 0.911, 'speaker': 'SPEAKER_00'}, {'word': 'the', 'start': 18.949, 'end': 19.009, 'score': 0.998, 'speaker': 'SPEAKER_00'}, {'word': 'ground', 'start': 19.029, 'end': 19.27, 'score': 0.874, 'speaker': 'SPEAKER_00'}, {'word': 'floor', 'start': 19.33, 'end': 19.591, 'score': 0.892, 'speaker': 'SPEAKER_00'}, {'word': 'which', 'start': 19.631, 'end': 19.792, 'score': 0.803, 'speaker': 'SPEAKER_00'}, {'word': 'served', 'start': 19.872, 'end': 20.113, 'score': 0.891, 'speaker': 'SPEAKER_00'}, {'word': 'the', 'start': 20.133, 'end': 20.193, 'score': 0.998, 'speaker': 'SPEAKER_00'}, {'word': 'best', 'start': 20.233, 'end': 20.394, 'score': 0.872, 'speaker': 'SPEAKER_00'}, {'word': 'biryani', 'start': 20.454, 'end': 20.855, 'score': 0.883, 'speaker': 'SPEAKER_00'}, {'word': 'in', 'start': 20.875, 'end': 20.975, 'score': 0.711, 'speaker': 'SPEAKER_00'}, {'word': 'Grant', 'start': 21.016, 'end': 21.256, 'score': 0.75, 'speaker': 'SPEAKER_00'}, {'word': 'Road', 'start': 21.317, 'end': 21.557, 'score': 0.659, 'speaker': 'SPEAKER_00'}, {'word': 'and', 'start': 21.617, 'end': 21.678, 'score': 0.546, 'speaker': 'SPEAKER_00'}, {'word': 'the', 'start': 21.698, 'end': 21.758, 'score': 0.696, 'speaker': 'SPEAKER_00'}, {'word': 'best', 'start': 21.798, 'end': 21.959, 'score': 0.892, 'speaker': 'SPEAKER_00'}, {'word': 'jalebis.', 'start': 21.999, 'end': 22.38, 'score': 0.729, 'speaker': 'SPEAKER_00'}, {'word': 'Okay.', 'start': 22.643, 'end': 22.914, 'score': 0.495, 'speaker': 'SPEAKER_00'}, {'word': 'My', 'start': 23.141, 'end': 23.403, 'score': 0.962, 'speaker': 'SPEAKER_00'}, {'word': 'two', 'start': 23.523, 'end': 23.685, 'score': 0.871, 'speaker': 'SPEAKER_00'}, {'word': 'aunts', 'start': 23.826, 'end': 24.067, 'score': 0.656, 'speaker': 'SPEAKER_00'}, {'word': 'and', 'start': 24.209, 'end': 24.289, 'score': 0.97, 'speaker': 'SPEAKER_00'}, {'word': 'my', 'start': 24.309, 'end': 24.43, 'score': 0.98, 'speaker': 'SPEAKER_00'}, {'word': 'mom', 'start': 24.47, 'end': 24.712, 'score': 0.768, 'speaker': 'SPEAKER_00'}, {'word': 'used', 'start': 24.833, 'end': 24.954, 'score': 0.874, 'speaker': 'SPEAKER_00'}, {'word': 'to', 'start': 24.994, 'end': 25.035, 'score': 0.988, 'speaker': 'SPEAKER_00'}, {'word': 'teach', 'start': 25.095, 'end': 25.297, 'score': 0.572, 'speaker': 'SPEAKER_00'}, {'word': 'the', 'start': 25.337, 'end': 25.417, 'score': 0.852, 'speaker': 'SPEAKER_00'}, {'word': 'piano.', 'start': 25.438, 'end': 25.74, 'score': 0.951, 'speaker': 'SPEAKER_00'}, {'word': 'So', 'start': 26.061, 'end': 26.101, 'score': 0.002, 'speaker': 'SPEAKER_00'}, {'word': 'I', 'start': 26.121, 'end': 26.201, 'score': 0.516, 'speaker': 'SPEAKER_00'}, {'word': 'think', 'start': 26.221, 'end': 26.362, 'score': 0.475, 'speaker': 'SPEAKER_00'}, {'word': 'all', 'start': 26.462, 'end': 26.603, 'score': 0.783, 'speaker': 'SPEAKER_00'}, {'word': 'my', 'start': 26.623, 'end': 26.743, 'score': 0.832, 'speaker': 'SPEAKER_00'}, {'word': 'first', 'start': 26.784, 'end': 27.045, 'score': 0.75, 'speaker': 'SPEAKER_00'}, {'word': 'few', 'start': 27.145, 'end': 27.346, 'score': 0.739, 'speaker': 'SPEAKER_00'}, {'word': 'girlfriends', 'start': 27.446, 'end': 27.888, 'score': 0.786, 'speaker': 'SPEAKER_00'}, {'word': 'were', 'start': 27.928, 'end': 28.069, 'score': 0.985, 'speaker': 'SPEAKER_00'}, {'word': 'all', 'start': 28.149, 'end': 28.269, 'score': 0.953, 'speaker': 'SPEAKER_00'}, {'word': 'piano', 'start': 28.289, 'end': 28.791, 'score': 0.665, 'speaker': 'SPEAKER_00'}, {'word': 'students', 'start': 28.811, 'end': 29.153, 'score': 0.363, 'speaker': 'SPEAKER_00'}, {'word': 'that', 'start': 29.173, 'end': 29.333, 'score': 0.402, 'speaker': 'SPEAKER_00'}, {'word': 'would', 'start': 29.374, 'end': 29.615, 'score': 0.486, 'speaker': 'SPEAKER_00'}, {'word': 'come', 'start': 29.655, 'end': 30.478, 'score': 0.623, 'speaker': 'SPEAKER_00'}, {'word': 'there.', 'start': 30.498, 'end': 30.699, 'score': 0.505, 'speaker': 'SPEAKER_00'}, {'word': 'Did', 'start': 31.841, 'end': 31.962, 'score': 0.389, 'speaker': 'SPEAKER_00'}, {'word': 'you', 'start': 32.003, 'end': 32.104, 'score': 0.842, 'speaker': 'SPEAKER_00'}, {'word': 'learn', 'start': 32.246, 'end': 32.489, 'score': 0.464, 'speaker': 'SPEAKER_00'}, {'word': 'to', 'start': 32.509, 'end': 32.59, 'score': 0.809, 'speaker': 'SPEAKER_00'}, {'word': 'impress', 'start': 32.61, 'end': 32.853, 'score': 0.28, 'speaker': 'SPEAKER_00'}, {'word': 'them?', 'start': 32.873, 'end': 32.954, 'score': 0.426, 'speaker': 'SPEAKER_00'}, {'word': 'Yes,', 'start': 33.54, 'end': 33.741, 'score': 0.953, 'speaker': 'SPEAKER_00'}, {'word': 'I', 'start': 34.123, 'end': 34.203, 'score': 0.852, 'speaker': 'SPEAKER_00'}, {'word': 'learned', 'start': 34.223, 'end': 34.444, 'score': 0.775, 'speaker': 'SPEAKER_00'}, {'word': 'how', 'start': 34.464, 'end': 34.545, 'score': 0.99, 'speaker': 'SPEAKER_00'}, {'word': 'to', 'start': 34.585, 'end': 34.625, 'score': 0.998, 'speaker': 'SPEAKER_00'}, {'word': 'play', 'start': 34.665, 'end': 34.846, 'score': 0.73, 'speaker': 'SPEAKER_00'}, {'word': 'the', 'start': 34.906, 'end': 34.986, 'score': 0.83, 'speaker': 'SPEAKER_00'}, {'word': 'piano', 'start': 35.227, 'end': 35.589, 'score': 0.952, 'speaker': 'SPEAKER_00'}, {'word': 'in', 'start': 35.75, 'end': 35.83, 'score': 0.832, 'speaker': 'SPEAKER_00'}, {'word': 'the', 'start': 35.85, 'end': 35.93, 'score': 0.824, 'speaker': 'SPEAKER_00'}, {'word': 'process,', 'start': 35.971, 'end': 36.392, 'score': 0.862, 'speaker': 'SPEAKER_00'}, {'word': 'but', 'start': 36.412, 'end': 36.533, 'score': 0.877, 'speaker': 'SPEAKER_00'}, {'word': 'that', 'start': 36.573, 'end': 36.714, 'score': 0.898, 'speaker': 'SPEAKER_00'}, {'word': 'is', 'start': 36.774, 'end': 36.834, 'score': 0.758, 'speaker': 'SPEAKER_00'}, {'word': 'compliments', 'start': 36.874, 'end': 37.336, 'score': 0.872, 'speaker': 'SPEAKER_00'}, {'word': 'to', 'start': 37.376, 'end': 37.437, 'score': 0.811, 'speaker': 'SPEAKER_00'}, {'word': 'my', 'start': 37.477, 'end': 37.577, 'score': 0.98, 'speaker': 'SPEAKER_00'}, {'word': 'mom', 'start': 37.617, 'end': 37.798, 'score': 0.814, 'speaker': 'SPEAKER_00'}, {'word': 'and', 'start': 37.818, 'end': 37.899, 'score': 0.41, 'speaker': 'SPEAKER_00'}, {'word': 'my', 'start': 37.919, 'end': 38.059, 'score': 0.98, 'speaker': 'SPEAKER_00'}, {'word': 'aunts.', 'start': 38.14, 'end': 38.24, 'score': 0.026, 'speaker': 'SPEAKER_00'}, {'word': 'Not', 'start': 39.864, 'end': 40.025, 'score': 0.886, 'speaker': 'SPEAKER_00'}, {'word': 'the', 'start': 40.045, 'end': 40.125, 'score': 0.92, 'speaker': 'SPEAKER_00'}, {'word': 'girlfriends,', 'start': 40.165, 'end': 40.667, 'score': 0.561, 'speaker': 'SPEAKER_00'}, {'word': 'but', 'start': 40.747, 'end': 40.868, 'score': 0.992, 'speaker': 'SPEAKER_00'}, {'word': 'very', 'start': 40.948, 'end': 41.149, 'score': 0.865, 'speaker': 'SPEAKER_00'}, {'word': 'very', 'start': 41.189, 'end': 41.389, 'score': 0.77, 'speaker': 'SPEAKER_00'}, {'word': 'fond', 'start': 41.45, 'end': 41.67, 'score': 0.861, 'speaker': 'SPEAKER_00'}, {'word': 'memories', 'start': 41.731, 'end': 42.132, 'score': 0.879, 'speaker': 'SPEAKER_00'}, {'word': 'and', 'start': 42.373, 'end': 42.453, 'score': 0.958, 'speaker': 'SPEAKER_00'}, {'word': \"that's\", 'start': 42.513, 'end': 42.694, 'score': 0.93, 'speaker': 'SPEAKER_00'}, {'word': 'why', 'start': 42.734, 'end': 42.854, 'score': 0.892, 'speaker': 'SPEAKER_00'}, {'word': 'I', 'start': 42.895, 'end': 42.955, 'score': 0.344, 'speaker': 'SPEAKER_00'}, {'word': 'meant', 'start': 43.015, 'end': 43.236, 'score': 0.673, 'speaker': 'SPEAKER_00'}, {'word': 'that', 'start': 43.677, 'end': 43.798, 'score': 0.916, 'speaker': 'SPEAKER_00'}, {'word': 'you', 'start': 43.838, 'end': 43.938, 'score': 0.945, 'speaker': 'SPEAKER_00'}, {'word': 'get', 'start': 43.978, 'end': 44.099, 'score': 0.908, 'speaker': 'SPEAKER_00'}, {'word': 'grounded.', 'start': 44.139, 'end': 44.44, 'score': 0.749, 'speaker': 'SPEAKER_00'}, {'word': 'You', 'start': 44.66, 'end': 44.72, 'score': 0.996, 'speaker': 'SPEAKER_00'}, {'word': 'know,', 'start': 44.741, 'end': 44.861, 'score': 0.939, 'speaker': 'SPEAKER_00'}, {'word': 'then', 'start': 44.901, 'end': 45.021, 'score': 0.801, 'speaker': 'SPEAKER_00'}, {'word': 'your', 'start': 45.041, 'end': 45.202, 'score': 0.879, 'speaker': 'SPEAKER_00'}, {'word': 'expectation', 'start': 45.282, 'end': 45.924, 'score': 0.94, 'speaker': 'SPEAKER_00'}, {'word': 'on', 'start': 45.984, 'end': 46.104, 'score': 0.622, 'speaker': 'SPEAKER_00'}, {'word': 'life', 'start': 46.185, 'end': 46.466, 'score': 0.97, 'speaker': 'SPEAKER_00'}, {'word': 'is', 'start': 46.626, 'end': 46.686, 'score': 0.75, 'speaker': 'SPEAKER_00'}, {'word': 'everything', 'start': 46.746, 'end': 46.987, 'score': 0.967, 'speaker': 'SPEAKER_00'}, {'word': 'is', 'start': 47.047, 'end': 47.168, 'score': 0.673, 'speaker': 'SPEAKER_00'}, {'word': 'up', 'start': 47.809, 'end': 47.91, 'score': 0.852, 'speaker': 'SPEAKER_00'}, {'word': 'there', 'start': 47.99, 'end': 48.251, 'score': 0.762, 'speaker': 'SPEAKER_00'}, {'word': 'and', 'start': 48.552, 'end': 48.632, 'score': 0.984, 'speaker': 'SPEAKER_00'}, {'word': 'I', 'start': 48.672, 'end': 48.732, 'score': 0.913, 'speaker': 'SPEAKER_00'}, {'word': 'think', 'start': 48.772, 'end': 48.953, 'score': 0.701, 'speaker': 'SPEAKER_00'}, {'word': 'many', 'start': 49.575, 'end': 49.795, 'score': 0.863, 'speaker': 'SPEAKER_00'}, {'word': 'of', 'start': 49.815, 'end': 49.875, 'score': 0.748, 'speaker': 'SPEAKER_00'}, {'word': 'the', 'start': 49.916, 'end': 49.996, 'score': 0.975, 'speaker': 'SPEAKER_00'}, {'word': 'times', 'start': 50.036, 'end': 50.297, 'score': 0.812, 'speaker': 'SPEAKER_00'}, {'word': 'when', 'start': 50.337, 'end': 50.437, 'score': 0.999, 'speaker': 'SPEAKER_00'}, {'word': \"I've\", 'start': 50.457, 'end': 50.618, 'score': 0.642, 'speaker': 'SPEAKER_00'}, {'word': 'been', 'start': 50.638, 'end': 50.798, 'score': 0.842, 'speaker': 'SPEAKER_00'}, {'word': 'set', 'start': 50.858, 'end': 51.079, 'score': 0.855, 'speaker': 'SPEAKER_00'}, {'word': 'back', 'start': 51.219, 'end': 51.44, 'score': 0.264, 'speaker': 'SPEAKER_00'}, {'word': 'my', 'start': 52.301, 'end': 52.482, 'score': 0.946, 'speaker': 'SPEAKER_00'}, {'word': 'introspection', 'start': 52.764, 'end': 53.388, 'score': 0.92, 'speaker': 'SPEAKER_00'}, {'word': 'was', 'start': 53.428, 'end': 53.63, 'score': 0.877, 'speaker': 'SPEAKER_00'}, {'word': 'now', 'start': 53.75, 'end': 53.912, 'score': 0.917, 'speaker': 'SPEAKER_00'}, {'word': 'how', 'start': 53.972, 'end': 54.193, 'score': 0.915, 'speaker': 'SPEAKER_00'}, {'word': 'worse', 'start': 54.334, 'end': 54.656, 'score': 0.887, 'speaker': 'SPEAKER_00'}, {'word': 'can', 'start': 54.697, 'end': 54.878, 'score': 0.833, 'speaker': 'SPEAKER_00'}, {'word': 'it', 'start': 54.898, 'end': 54.938, 'score': 0.702, 'speaker': 'SPEAKER_00'}, {'word': 'get?', 'start': 55.079, 'end': 55.18, 'score': 0.222, 'speaker': 'SPEAKER_00'}, {'word': 'You', 'start': 55.76, 'end': 55.953, 'score': 0.007}]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\AppData\\Local\\Temp\\ipykernel_440\\47206666.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\neeraj\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_440\\\\47206666.py'</span>                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\neeraj\\AppData\\Local\\Temp\\ipykernel_440\\2744413152.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">26</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">assign_speakers</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\neeraj\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_440\\\\2744413152.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'speaker'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\AppData\\Local\\Temp\\ipykernel_440\\47206666.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'C:\\\\Users\\\\neeraj\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_440\\\\47206666.py'\u001b[0m                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\neeraj\\AppData\\Local\\Temp\\ipykernel_440\\2744413152.py\u001b[0m:\u001b[94m26\u001b[0m in \u001b[92massign_speakers\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'C:\\\\Users\\\\neeraj\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_440\\\\2744413152.py'\u001b[0m                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'speaker'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_segments_w_speakers = assign_speakers(diarization_result, aligned_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf2e31e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe009988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
